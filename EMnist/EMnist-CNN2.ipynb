{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce3ea746-73ef-48d5-aa6c-ab067a72e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "#Используем костыль для исправления IntelliSense для keras по гайду:\n",
    "#https://stackoverflow.com/questions/71000250/import-tensorflow-keras-could-not-be-resolved-after-upgrading-to-tensorflow-2\n",
    "import keras.api._v2.keras as keras\n",
    "from keras import layers\n",
    "from keras import losses\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from emnist import list_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b69d7948-26fb-454c-8257-28ada65466f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['balanced', 'byclass', 'bymerge', 'digits', 'letters', 'mnist']\n",
      "\n",
      "Train X=(697932, 28, 28, 1), y=(697932, 62)\n",
      "Train X=(697932, 28, 28, 1), y=(697932, 62)\n",
      "Test X=(10000, 28, 28, 1), y=(10000, 62)\n",
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(list_datasets())\n",
    "\n",
    "(x_train,y_train), (x_test,y_test)=mnist.load_data()\n",
    "\n",
    "from emnist import extract_training_samples\n",
    "#x_train, y_train = extract_training_samples('digits')\n",
    "x_train, y_train = extract_training_samples('byclass')\n",
    "#x_train, y_train = extract_training_samples('letters')\n",
    "\n",
    "num_classes=62#10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "x_train=x_train.astype('float32')/255.0\n",
    "x_test=x_test.astype('float32')/255.0\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#x_train_l, y_train_l = extract_training_samples('letters')\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"Train X=%s, y=%s\"%(x_train.shape,y_train.shape))\n",
    "#print(\"Train Letters X=%s, y=%s\"%(x_train_l.shape,y_train_l.shape))\n",
    "#print(\"Test X=%s, y=%s\"%(x_test1.shape,y_test.shape))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Train X=%s, y=%s\"%(x_train.shape,y_train.shape))\n",
    "print(\"Test X=%s, y=%s\"%(x_test.shape,y_test.shape))\n",
    "print(x_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4415ec0d-cc5a-4cab-b2ff-27ea927c103f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 62)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 15, 15, 32)        6304      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 7, 7, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 1, 1, 64)          100416    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 62)                4030      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110,750\n",
      "Trainable params: 110,750\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(14, 14), activation=\"relu\",use_bias=True,\n",
    "                                        kernel_initializer=tf.keras.initializers.glorot_normal(),\n",
    "                                        bias_initializer=tf.keras.initializers.zeros()),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(7, 7), activation=\"relu\",use_bias=True,\n",
    "                                        kernel_initializer=tf.keras.initializers.glorot_normal(),\n",
    "                                        bias_initializer=tf.keras.initializers.zeros()),\n",
    "        #layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        #layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]#52 Буквы, 10 цифрф\n",
    " )\n",
    "print(model.output_shape)\n",
    "print(str(model.summary()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cecdd65d-85e3-4639-b128-63b390d07ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    #SparseCategoricalCrossentropy - ужастно работает на EMnist. CategoricalCrossentropy + категории топчик.\n",
    "    loss=losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f21720c-e21e-4bf7-a60b-369322b97eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x_train,y_train,batch_size=1,epochs=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cb85611-6ce1-425e-8bd3-0dd1bcb62ed7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train= (697932, 28, 28, 1) y_train (697932, 62)\n",
      "Epoch 1\n",
      "6980/6980 [==============================] - 162s 23ms/step - loss: 0.5879 - accuracy: 0.8084\n",
      "100/100 - 1s - loss: 0.6590 - accuracy: 0.8035 - 921ms/epoch - 9ms/step\n",
      "[0.6589698195457458, 0.8034999966621399]\n",
      "Epoch 2\n",
      "6980/6980 [==============================] - 159s 23ms/step - loss: 0.4396 - accuracy: 0.8447\n",
      "100/100 - 1s - loss: 0.7992 - accuracy: 0.6898 - 682ms/epoch - 7ms/step\n",
      "[0.7991771697998047, 0.6898000240325928]\n",
      "Epoch 3\n",
      "6980/6980 [==============================] - 159s 23ms/step - loss: 0.4152 - accuracy: 0.8513\n",
      "100/100 - 1s - loss: 0.6579 - accuracy: 0.7258 - 666ms/epoch - 7ms/step\n",
      "[0.6579175591468811, 0.7257999777793884]\n",
      "Epoch 4\n",
      "6980/6980 [==============================] - 151s 22ms/step - loss: 0.4021 - accuracy: 0.8547\n",
      "100/100 - 1s - loss: 0.5747 - accuracy: 0.7670 - 686ms/epoch - 7ms/step\n",
      "[0.574698269367218, 0.7670000195503235]\n",
      "Epoch 5\n",
      "6980/6980 [==============================] - 157s 23ms/step - loss: 0.3930 - accuracy: 0.8566\n",
      "100/100 - 1s - loss: 0.6565 - accuracy: 0.7569 - 652ms/epoch - 7ms/step\n",
      "[0.6565049886703491, 0.7569000124931335]\n",
      "Epoch 6\n",
      "6980/6980 [==============================] - 158s 23ms/step - loss: 0.3866 - accuracy: 0.8584\n",
      "100/100 - 1s - loss: 0.5671 - accuracy: 0.7614 - 696ms/epoch - 7ms/step\n",
      "[0.567063570022583, 0.7613999843597412]\n",
      "Epoch 7\n",
      "6980/6980 [==============================] - 160s 23ms/step - loss: 0.3816 - accuracy: 0.8594\n",
      "100/100 - 1s - loss: 0.5554 - accuracy: 0.7759 - 665ms/epoch - 7ms/step\n",
      "[0.5554183721542358, 0.7759000062942505]\n",
      "Epoch 8\n",
      "6980/6980 [==============================] - 157s 22ms/step - loss: 0.3767 - accuracy: 0.8607\n",
      "100/100 - 1s - loss: 0.7688 - accuracy: 0.7067 - 684ms/epoch - 7ms/step\n",
      "[0.7688184976577759, 0.7067000269889832]\n",
      "Epoch 9\n",
      "6980/6980 [==============================] - 161s 23ms/step - loss: 0.3731 - accuracy: 0.8617\n",
      "100/100 - 1s - loss: 0.7931 - accuracy: 0.6980 - 686ms/epoch - 7ms/step\n",
      "[0.7930987477302551, 0.6980000138282776]\n",
      "Epoch 10\n",
      "6980/6980 [==============================] - 161s 23ms/step - loss: 0.3696 - accuracy: 0.8629\n",
      "100/100 - 1s - loss: 0.6707 - accuracy: 0.7373 - 681ms/epoch - 7ms/step\n",
      "[0.6706898212432861, 0.7372999787330627]\n",
      "Epoch 11\n",
      "6980/6980 [==============================] - 159s 23ms/step - loss: 0.3667 - accuracy: 0.8635\n",
      "100/100 - 1s - loss: 0.6277 - accuracy: 0.7470 - 671ms/epoch - 7ms/step\n",
      "[0.6276894807815552, 0.746999979019165]\n",
      "Epoch 12\n",
      "6980/6980 [==============================] - 160s 23ms/step - loss: 0.3643 - accuracy: 0.8641\n",
      "100/100 - 1s - loss: 0.6186 - accuracy: 0.7750 - 686ms/epoch - 7ms/step\n",
      "[0.6186304688453674, 0.7749999761581421]\n",
      "Epoch 13\n",
      "6980/6980 [==============================] - 167s 24ms/step - loss: 0.3615 - accuracy: 0.8647\n",
      "100/100 - 1s - loss: 0.7831 - accuracy: 0.7283 - 765ms/epoch - 8ms/step\n",
      "[0.7830522656440735, 0.7282999753952026]\n",
      "Epoch 14\n",
      "6980/6980 [==============================] - 164s 23ms/step - loss: 0.3594 - accuracy: 0.8651\n",
      "100/100 - 1s - loss: 0.5734 - accuracy: 0.7912 - 714ms/epoch - 7ms/step\n",
      "[0.5734291672706604, 0.7911999821662903]\n",
      "Epoch 15\n",
      "6980/6980 [==============================] - 167s 24ms/step - loss: 0.3573 - accuracy: 0.8658\n",
      "100/100 - 1s - loss: 0.7526 - accuracy: 0.7306 - 708ms/epoch - 7ms/step\n",
      "[0.7525535225868225, 0.7305999994277954]\n",
      "Epoch 16\n",
      "6980/6980 [==============================] - 166s 24ms/step - loss: 0.3554 - accuracy: 0.8663\n",
      "100/100 - 1s - loss: 0.5733 - accuracy: 0.7793 - 680ms/epoch - 7ms/step\n",
      "[0.5732697248458862, 0.7792999744415283]\n",
      "Epoch 17\n",
      "6980/6980 [==============================] - 165s 24ms/step - loss: 0.3535 - accuracy: 0.8669\n",
      "100/100 - 1s - loss: 0.6125 - accuracy: 0.7845 - 696ms/epoch - 7ms/step\n",
      "[0.6125345230102539, 0.784500002861023]\n",
      "Epoch 18\n",
      "6980/6980 [==============================] - 162s 23ms/step - loss: 0.3517 - accuracy: 0.8675\n",
      "100/100 - 1s - loss: 0.7910 - accuracy: 0.7411 - 690ms/epoch - 7ms/step\n",
      "[0.7909905910491943, 0.741100013256073]\n",
      "Epoch 19\n",
      "6980/6980 [==============================] - 165s 24ms/step - loss: 0.3505 - accuracy: 0.8677\n",
      "100/100 - 1s - loss: 0.7004 - accuracy: 0.7564 - 680ms/epoch - 7ms/step\n",
      "[0.7004328370094299, 0.7563999891281128]\n",
      "Epoch 20\n",
      "6980/6980 [==============================] - 167s 24ms/step - loss: 0.3486 - accuracy: 0.8682\n",
      "100/100 - 1s - loss: 0.7653 - accuracy: 0.7348 - 664ms/epoch - 7ms/step\n",
      "[0.7652536630630493, 0.7347999811172485]\n",
      "Epoch 21\n",
      "6980/6980 [==============================] - 159s 23ms/step - loss: 0.3467 - accuracy: 0.8687\n",
      "100/100 - 1s - loss: 0.7250 - accuracy: 0.7362 - 711ms/epoch - 7ms/step\n",
      "[0.7250146269798279, 0.7361999750137329]\n",
      "Epoch 22\n",
      "6980/6980 [==============================] - 164s 24ms/step - loss: 0.3458 - accuracy: 0.8687\n",
      "100/100 - 1s - loss: 0.7184 - accuracy: 0.7372 - 699ms/epoch - 7ms/step\n",
      "[0.7184397578239441, 0.7372000217437744]\n",
      "Epoch 23\n",
      "6980/6980 [==============================] - 167s 24ms/step - loss: 0.3448 - accuracy: 0.8687\n",
      "100/100 - 1s - loss: 0.8102 - accuracy: 0.7289 - 673ms/epoch - 7ms/step\n",
      "[0.810154378414154, 0.7289000153541565]\n",
      "Epoch 24\n",
      "6980/6980 [==============================] - 165s 24ms/step - loss: 0.3432 - accuracy: 0.8694\n",
      "100/100 - 1s - loss: 0.7556 - accuracy: 0.7392 - 726ms/epoch - 7ms/step\n",
      "[0.7556397318840027, 0.7391999959945679]\n",
      "Epoch 25\n",
      "6980/6980 [==============================] - 167s 24ms/step - loss: 0.3420 - accuracy: 0.8698\n",
      "100/100 - 1s - loss: 0.9437 - accuracy: 0.7002 - 675ms/epoch - 7ms/step\n",
      "[0.9436596632003784, 0.7002000212669373]\n",
      "Epoch 26\n",
      "6980/6980 [==============================] - 165s 24ms/step - loss: 0.3405 - accuracy: 0.8705\n",
      "100/100 - 1s - loss: 0.7653 - accuracy: 0.7273 - 686ms/epoch - 7ms/step\n",
      "[0.7652726769447327, 0.7272999882698059]\n",
      "Epoch 27\n",
      "6980/6980 [==============================] - 158s 22ms/step - loss: 0.3399 - accuracy: 0.8705\n",
      "100/100 - 1s - loss: 0.8792 - accuracy: 0.7114 - 719ms/epoch - 7ms/step\n",
      "[0.8791881799697876, 0.7113999724388123]\n",
      "Epoch 28\n",
      "6980/6980 [==============================] - 166s 24ms/step - loss: 0.3389 - accuracy: 0.8710\n",
      "100/100 - 1s - loss: 0.7248 - accuracy: 0.7544 - 695ms/epoch - 7ms/step\n",
      "[0.7247872948646545, 0.7544000148773193]\n",
      "Epoch 29\n",
      "6980/6980 [==============================] - 164s 23ms/step - loss: 0.3383 - accuracy: 0.8710\n",
      "100/100 - 1s - loss: 0.7352 - accuracy: 0.7657 - 692ms/epoch - 7ms/step\n",
      "[0.7352158427238464, 0.7656999826431274]\n",
      "Epoch 30\n",
      "6980/6980 [==============================] - 167s 24ms/step - loss: 0.3368 - accuracy: 0.8711\n",
      "100/100 - 1s - loss: 0.9122 - accuracy: 0.7163 - 709ms/epoch - 7ms/step\n",
      "[0.912209153175354, 0.7163000106811523]\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train=\",x_train.shape,\"y_train\",y_train.shape)\n",
    "model.save(\"saved_model_CNN2/EMNIST_learn_epoch_start.h5\")\n",
    "for i in range(1,31):\n",
    "    print(\"Epoch \"+str(i))\n",
    "    model.save('saved_model_CNN2/EMNIST_learn_epoch_start='+str(i)+\".h5\")\n",
    "    model.fit(x_train,y_train,batch_size=100,epochs=1,shuffle=True)\n",
    "    #,validation_data=(x_test,y_test)\n",
    "    results=model.evaluate(x_test,y_test,batch_size=100,verbose=2)\n",
    "    print(str(results))\n",
    "    model.save('saved_model_CNN2/EMNIST_learn_epoch_end='+str(i)+\".h5\")\n",
    "model.save(\"saved_model_CNN2/EMNIST_learn_done.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d414d1e4-01df-4018-9c15-6d3af2ca3bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model.fit(x_train,y_train,batch_size=32,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80a0a9c-40f1-460b-b3ed-4740bb659edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25924428-dbef-47ca-9819-544f29745779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights(\"saved_model3/EMNIST_learn_epoch_start.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6186a282-2204-4b0e-8bd2-c08bd411cf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 3s - loss: 0.9122 - accuracy: 0.7163 - 3s/epoch - 9ms/step\n",
      "[0.9122095704078674, 0.7163000106811523]\n",
      "641\n"
     ]
    }
   ],
   "source": [
    "results=model.evaluate(x_test,y_test,batch_size=32,verbose=2)\n",
    "print(str(results))\n",
    "value=np.random.randint(0,10000)\n",
    "print(value)\n",
    "for id in range(len(y_train)):\n",
    "    #print(labels[id])\n",
    "    #break\n",
    "    #22 - M big\n",
    "    if(y_train.argmax()==8):\n",
    "        value=id\n",
    "        break\n",
    "        \n",
    "\n",
    "\n",
    "#print(x_train[value].shape)\n",
    "\n",
    "single=x_train[value]\n",
    "image=np.zeros((28,28,3))\n",
    "print(image.shape)\n",
    "\n",
    "for y in range(0,image.shape[0]):\n",
    "    for x in range(0,image.shape[1]):\n",
    "        for c in range(0,image.shape[2]):\n",
    "            image[y,x,c]=single[y][x]\n",
    "\n",
    "\n",
    "\n",
    "print(single.shape)\n",
    "#print(single)\n",
    "\n",
    "singleReady=np.zeros((1,28,28))\n",
    "\n",
    "for y in range(0,image.shape[0]):\n",
    "    for x in range(0,image.shape[1]):\n",
    "            singleReady[0][y][x]=single[y][x]\n",
    "\n",
    "print(model.predict(singleReady,batch_size=1).argmax())\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90177ee-7111-49bd-87de-fd4323a5947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_model_CNN2/EMNIST_byclass_done.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f6ad4b-c994-4c6b-9412-9b84fa1e51c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results=model.evaluate(x_test,y_test,batch_size=32,verbose=2)\n",
    "#print(str(results))\n",
    "#value=np.random.randint(0,10000)\n",
    "\n",
    "id=22\n",
    "for v in y_train:\n",
    "    if(v.argmax()==id):\n",
    "        print(id)\n",
    "        ShowImage(v)\n",
    "        break\n",
    "        #id+=1\n",
    "currentIteration=0\n",
    "'''for v in y_train:\n",
    "    if(v==id):\n",
    "        print(id,v)\n",
    "        ShowImage(v)\n",
    "        currentIteration+=1\n",
    "        id+=1    \n",
    "    if(currentIteration==10):\n",
    "        break'''\n",
    "\n",
    "\n",
    "def ShowImage(value:int):\n",
    "    print(x_train[value].shape)\n",
    "\n",
    "    single=x_train[value]\n",
    "    image=np.zeros((28,28,3))\n",
    "    print(image.shape)\n",
    "\n",
    "    for y in range(0,image.shape[0]):\n",
    "        for x in range(0,image.shape[1]):\n",
    "            for c in range(0,image.shape[2]):\n",
    "                image[y,x,c]=single[y*28+x]\n",
    "\n",
    "\n",
    "\n",
    "    #print(single.shape)\n",
    "    #print(single)\n",
    "\n",
    "    #singleReady=np.zeros((1,28*28))\n",
    "\n",
    "    #for y in range(0,image.shape[0]):\n",
    "    #    for x in range(0,image.shape[1]):\n",
    "    #            singleReady[0][y*28+x]=single[y*28+x]\n",
    "\n",
    "    #print(model.predict(singleReady,batch_size=1).argmax())\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d82074-35d5-4ed4-842c-8f9e6e7a81ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
