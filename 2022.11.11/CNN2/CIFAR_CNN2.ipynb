{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce3ea746-73ef-48d5-aa6c-ab067a72e8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PlayerPC\\Miniconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "#Используем костыль для исправления IntelliSense для keras по гайду:\n",
    "#https://stackoverflow.com/questions/71000250/import-tensorflow-keras-could-not-be-resolved-after-upgrading-to-tensorflow-2\n",
    "import keras.api._v2.keras as keras\n",
    "from keras import layers\n",
    "from keras import losses\n",
    "#from keras.datasets import CIFAR100\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b69d7948-26fb-454c-8257-28ada65466f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train X=(50000, 32, 32, 3, 1), y=(50000, 100)\n",
      "Train X=(50000, 32, 32, 3, 1), y=(50000, 100)\n",
      "Test X=(10000, 32, 32, 3, 1), y=(10000, 100)\n",
      "(32, 32, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "#(x_train,y_train), (x_test,y_test)=CIFAR100.load_data()\n",
    "'''print(tfds.load('cifar100', split='train', shuffle_files=True,as_supervised=True))\n",
    "\n",
    "builder = tfds.builder('cifar100')\n",
    "info = builder.info\n",
    "print(info)\n",
    "\n",
    "\n",
    "x_train, y_train = tfds.as_numpy(tfds.load('cifar100', split='train', shuffle_files=True,as_supervised=True))'''\n",
    "#x_test, y_test = tfds.as_numpy(tfds.load('cifar100', split='test', shuffle_files=True))\n",
    "#print(ds)\n",
    "\n",
    "#from eCIFAR100 import extract_training_samples\n",
    "#x_train, y_train = extract_training_samples('digits')\n",
    "#x_train, y_train = extract_training_samples('byclass')\n",
    "#x_train, y_train = extract_training_samples('letters')\n",
    "\n",
    "num_classes=100\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "x_train=x_train.astype('float32')/255.0\n",
    "x_test=x_test.astype('float32')/255.0\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#x_train_l, y_train_l = extract_training_samples('letters')\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"Train X=%s, y=%s\"%(x_train.shape,y_train.shape))\n",
    "#print(\"Train Letters X=%s, y=%s\"%(x_train_l.shape,y_train_l.shape))\n",
    "#print(\"Test X=%s, y=%s\"%(x_test1.shape,y_test.shape))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Train X=%s, y=%s\"%(x_train.shape,y_train.shape))\n",
    "print(\"Test X=%s, y=%s\"%(x_test.shape,y_test.shape))\n",
    "print(x_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4415ec0d-cc5a-4cab-b2ff-27ea927c103f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 100)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_7 (Batc  (None, 32, 32, 3)        12        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 32)        2432      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 14, 14, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 12, 12, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 12, 12, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 12, 12, 32)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 10, 10, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 10, 10, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 10, 10, 32)        0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 8, 8, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 6, 6, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 3, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 3, 3, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 3, 3, 64)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 576)              2304      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               57700     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 137,264\n",
      "Trainable params: 135,658\n",
      "Non-trainable params: 1,606\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\",use_bias=True),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\",use_bias=True),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        #layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\",use_bias=True),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\",use_bias=True),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\",use_bias=True),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        #layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.BatchNormalization(),\n",
    "        #layers.Dropout(0.4),\n",
    "        #layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]#52 Буквы, 10 цифрф\n",
    " )\n",
    "print(model.output_shape)\n",
    "print(str(model.summary()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cecdd65d-85e3-4639-b128-63b390d07ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.optimizers.Adam(lr=0.01),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f21720c-e21e-4bf7-a60b-369322b97eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 2.6951 - accuracy: 0.3243\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 23s 12ms/step - loss: 2.6687 - accuracy: 0.3305\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 2.6528 - accuracy: 0.3355\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 2.6387 - accuracy: 0.3375\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 2.6281 - accuracy: 0.3402\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 2.6066 - accuracy: 0.3436\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 2.5891 - accuracy: 0.3458\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 2.5755 - accuracy: 0.3505\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 2.5681 - accuracy: 0.3494\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 2.5562 - accuracy: 0.3518\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - 23s 12ms/step - loss: 2.5527 - accuracy: 0.3539\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 2.5317 - accuracy: 0.3565\n",
      "Epoch 13/50\n",
      "2000/2000 [==============================] - 23s 12ms/step - loss: 2.5338 - accuracy: 0.3587\n",
      "Epoch 14/50\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 2.5042 - accuracy: 0.3653\n",
      "Epoch 15/50\n",
      "2000/2000 [==============================] - 23s 12ms/step - loss: 2.4999 - accuracy: 0.3645\n",
      "Epoch 16/50\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 2.4989 - accuracy: 0.3654\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 2.4760 - accuracy: 0.3699\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - 23s 12ms/step - loss: 2.4719 - accuracy: 0.3727\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 2.4708 - accuracy: 0.3702\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 2.4619 - accuracy: 0.3747\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - 23s 12ms/step - loss: 2.4588 - accuracy: 0.3719\n",
      "Epoch 22/50\n",
      "2000/2000 [==============================] - 23s 12ms/step - loss: 2.4529 - accuracy: 0.3751\n",
      "Epoch 23/50\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 2.4464 - accuracy: 0.3750\n",
      "Epoch 24/50\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 2.4422 - accuracy: 0.3766\n",
      "Epoch 25/50\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 2.4235 - accuracy: 0.3794\n",
      "Epoch 26/50\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 2.4163 - accuracy: 0.3843\n",
      "Epoch 27/50\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 2.4257 - accuracy: 0.3792\n",
      "Epoch 28/50\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 2.4081 - accuracy: 0.3858\n",
      "Epoch 29/50\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 2.4102 - accuracy: 0.3831\n",
      "Epoch 30/50\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 2.3998 - accuracy: 0.3846\n",
      "Epoch 31/50\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 2.3999 - accuracy: 0.3839\n",
      "Epoch 32/50\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 2.3836 - accuracy: 0.3901\n",
      "Epoch 33/50\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 2.3804 - accuracy: 0.3901\n",
      "Epoch 34/50\n",
      "2000/2000 [==============================] - 23s 12ms/step - loss: 2.3917 - accuracy: 0.3883\n",
      "Epoch 35/50\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 2.3857 - accuracy: 0.3877\n",
      "Epoch 36/50\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 2.3693 - accuracy: 0.3931\n",
      "Epoch 37/50\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 2.3803 - accuracy: 0.3925\n",
      "Epoch 38/50\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 2.3671 - accuracy: 0.3912\n",
      "Epoch 39/50\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 2.3686 - accuracy: 0.3919\n",
      "Epoch 40/50\n",
      "2000/2000 [==============================] - 23s 12ms/step - loss: 2.3569 - accuracy: 0.3949\n",
      "Epoch 41/50\n",
      "2000/2000 [==============================] - 23s 11ms/step - loss: 2.3508 - accuracy: 0.3969\n",
      "Epoch 42/50\n",
      "2000/2000 [==============================] - 23s 12ms/step - loss: 2.3486 - accuracy: 0.3963\n",
      "Epoch 43/50\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 2.3480 - accuracy: 0.3993\n",
      "Epoch 44/50\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 2.3498 - accuracy: 0.3978\n",
      "Epoch 45/50\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 2.3410 - accuracy: 0.3993\n",
      "Epoch 46/50\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 2.3351 - accuracy: 0.3996\n",
      "Epoch 47/50\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 2.3444 - accuracy: 0.3976\n",
      "Epoch 48/50\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 2.3393 - accuracy: 0.3977\n",
      "Epoch 49/50\n",
      "2000/2000 [==============================] - 23s 12ms/step - loss: 2.3377 - accuracy: 0.3971\n",
      "Epoch 50/50\n",
      "2000/2000 [==============================] - 23s 12ms/step - loss: 2.3339 - accuracy: 0.3986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x239c6513fa0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=25,epochs=50,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cb85611-6ce1-425e-8bd3-0dd1bcb62ed7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train= (50000, 32, 32, 3, 1) y_train (50000, 100)\n",
      "Epoch 6\n",
      "2000/2000 [==============================] - 25s 11ms/step - loss: 4.0480 - accuracy: 0.0988 - val_loss: 3.7168 - val_accuracy: 0.1441\n",
      "Epoch 7\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 3.5611 - accuracy: 0.1625 - val_loss: 3.3672 - val_accuracy: 0.1979\n",
      "Epoch 8\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 3.3594 - accuracy: 0.1972 - val_loss: 3.1157 - val_accuracy: 0.2406\n",
      "Epoch 9\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 3.2016 - accuracy: 0.2261 - val_loss: 3.1490 - val_accuracy: 0.2481\n",
      "Epoch 10\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 3.0981 - accuracy: 0.2481 - val_loss: 2.9972 - val_accuracy: 0.2696\n",
      "Epoch 11\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 3.0024 - accuracy: 0.2657 - val_loss: 2.8843 - val_accuracy: 0.2807\n",
      "Epoch 12\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 2.9431 - accuracy: 0.2757 - val_loss: 2.8061 - val_accuracy: 0.2996\n",
      "Epoch 13\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 2.8902 - accuracy: 0.2880 - val_loss: 2.6856 - val_accuracy: 0.3282\n",
      "Epoch 14\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 2.8481 - accuracy: 0.2954 - val_loss: 2.6469 - val_accuracy: 0.3315\n",
      "Epoch 15\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 2.8050 - accuracy: 0.3008 - val_loss: 2.6507 - val_accuracy: 0.3366\n",
      "Epoch 16\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 2.7729 - accuracy: 0.3095 - val_loss: 2.6355 - val_accuracy: 0.3361\n",
      "Epoch 17\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 2.7475 - accuracy: 0.3132 - val_loss: 2.5058 - val_accuracy: 0.3530\n",
      "Epoch 18\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 2.7074 - accuracy: 0.3244 - val_loss: 2.5913 - val_accuracy: 0.3445\n",
      "Epoch 19\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i))\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved_model_CNN/CIFAR100_learn_epoch_start=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#,validation_data=(x_test,y_test)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved_model_CNN/CIFAR100_learn_epoch_end=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "print(\"x_train=\",x_train.shape,\"y_train\",y_train.shape)\n",
    "model.save(\"saved_model_CNN/CIFAR100_learn_epoch_start.h5\")\n",
    "for i in range(6,20):\n",
    "    print(\"Epoch \"+str(i))\n",
    "    model.save('saved_model_CNN/CIFAR100_learn_epoch_start='+str(i)+\".h5\")\n",
    "    model.fit(x_train,y_train,batch_size=25,epochs=1,shuffle=True,validation_data=(x_test,y_test))\n",
    "    #,validation_data=(x_test,y_test)\n",
    "    \n",
    "    \n",
    "    model.save('saved_model_CNN/CIFAR100_learn_epoch_end='+str(i)+\".h5\")\n",
    "results=model.evaluate(x_test,y_test,batch_size=25,verbose=2)\n",
    "print(str(results))\n",
    "model.save(\"saved_model_CNN/CIFAR100_learn_done.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d414d1e4-01df-4018-9c15-6d3af2ca3bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 2.6841 - accuracy: 0.3166 - val_loss: 2.4092 - val_accuracy: 0.3805\n",
      "Epoch 2\n",
      "2000/2000 [==============================] - 25s 12ms/step - loss: 2.6192 - accuracy: 0.3326 - val_loss: 2.3235 - val_accuracy: 0.3992\n",
      "Epoch 3\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 2.5756 - accuracy: 0.3422 - val_loss: 2.3266 - val_accuracy: 0.3917\n",
      "Epoch 4\n",
      "2000/2000 [==============================] - 25s 12ms/step - loss: 2.5368 - accuracy: 0.3513 - val_loss: 2.2805 - val_accuracy: 0.4020\n",
      "Epoch 5\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 2.4926 - accuracy: 0.3592 - val_loss: 2.2303 - val_accuracy: 0.4160\n",
      "Epoch 6\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i))\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved_model_CNN2/CIFAR100_learn_epoch_start=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#,validation_data=(x_test,y_test)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved_model_CNN2/CIFAR100_learn_epoch_end=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "#Без dropout было явное переобучение train 90 пртив test 45\n",
    "#print(\"x_train=\",x_train.shape,\"y_train\",y_train.shape)\n",
    "model.save(\"saved_model_CNN2/CIFAR100_learn_epoch_start.h5\")\n",
    "for i in range(1,10):\n",
    "    print(\"Epoch \"+str(i))\n",
    "    model.save('saved_model_CNN2/CIFAR100_learn_epoch_start='+str(i)+\".h5\")\n",
    "    model.fit(x_train,y_train,batch_size=25,epochs=1,shuffle=True,validation_data=(x_test,y_test))\n",
    "    #,validation_data=(x_test,y_test)\n",
    "    \n",
    "    \n",
    "    model.save('saved_model_CNN2/CIFAR100_learn_epoch_end='+str(i)+\".h5\")\n",
    "results=model.evaluate(x_test,y_test,batch_size=50,verbose=2)\n",
    "print(str(results))\n",
    "model.save(\"saved_model_CNN2/CIFAR100_learn_done.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed7edec0-1669-4bd8-b6a3-604a53d90ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"saved_model_CNN2/CIFAR100_learn_epoch_end=5.h5\")\n",
    "model.compile(\n",
    "    loss=losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08bed29c-82f0-4169-bbe2-523a994f4f3c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 2.4654 - accuracy: 0.3636 - val_loss: 2.2557 - val_accuracy: 0.4044\n",
      "Epoch 2\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 2.4352 - accuracy: 0.3732 - val_loss: 2.1714 - val_accuracy: 0.4271\n",
      "200/200 - 1s - loss: 2.1714 - accuracy: 0.4271 - 1s/epoch - 6ms/step\n",
      "[2.171410322189331, 0.4271000027656555]\n"
     ]
    }
   ],
   "source": [
    "#Без dropout было явное переобучение train 90 пртив test 45\n",
    "#print(\"x_train=\",x_train.shape,\"y_train\",y_train.shape)\n",
    "model.save(\"saved_model_CNN3/CIFAR100_learn_epoch_start.h5\")\n",
    "for i in range(1,3):\n",
    "    print(\"Epoch \"+str(i))\n",
    "    model.save('saved_model_CNN3/CIFAR100_learn_epoch_start='+str(i)+\".h5\")\n",
    "    model.fit(x_train,y_train,batch_size=25,epochs=1,shuffle=True,validation_data=(x_test,y_test))\n",
    "    #,validation_data=(x_test,y_test)\n",
    "    \n",
    "    \n",
    "    model.save('saved_model_CNN3/CIFAR100_learn_epoch_end='+str(i)+\".h5\")\n",
    "results=model.evaluate(x_test,y_test,batch_size=50,verbose=2)\n",
    "print(str(results))\n",
    "model.save(\"saved_model_CNN3/CIFAR100_learn_done.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abb69608-41e0-4105-b3c8-b0447329e157",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 2.2733 - accuracy: 0.4042 - val_loss: 2.0921 - val_accuracy: 0.4448\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 2.2472 - accuracy: 0.4129 - val_loss: 2.0666 - val_accuracy: 0.4476\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 2.2369 - accuracy: 0.4140 - val_loss: 2.0645 - val_accuracy: 0.4525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21230fec250>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=32,epochs=3,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b80a0a9c-40f1-460b-b3ed-4740bb659edf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 2.2209 - accuracy: 0.4157 - val_loss: 2.0795 - val_accuracy: 0.4492\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 2.1991 - accuracy: 0.4184 - val_loss: 2.0522 - val_accuracy: 0.4523\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 2.1925 - accuracy: 0.4217 - val_loss: 2.0335 - val_accuracy: 0.4567\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 2.1743 - accuracy: 0.4239 - val_loss: 2.0213 - val_accuracy: 0.4585\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 2.1636 - accuracy: 0.4289 - val_loss: 2.0201 - val_accuracy: 0.4609\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 2.1494 - accuracy: 0.4331 - val_loss: 2.0042 - val_accuracy: 0.4644\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 2.1429 - accuracy: 0.4324 - val_loss: 1.9779 - val_accuracy: 0.4688\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 2.1234 - accuracy: 0.4359 - val_loss: 2.0180 - val_accuracy: 0.4634\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 2.1186 - accuracy: 0.4369 - val_loss: 1.9869 - val_accuracy: 0.4673\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 2.1042 - accuracy: 0.4402 - val_loss: 1.9789 - val_accuracy: 0.4706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2104d3a9d60>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=32,epochs=10,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25924428-dbef-47ca-9819-544f29745779",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('CIFAR100_1.h5')\n",
    "#model.load_weights(\"saved_model3/ECIFAR100_learn_epoch_start.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32ff63f4-8bbf-4cd2-945a-c424def2d8ae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 2.0942 - accuracy: 0.4418 - val_loss: 1.9700 - val_accuracy: 0.4715\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 2.0925 - accuracy: 0.4433 - val_loss: 1.9655 - val_accuracy: 0.4738\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 2.0743 - accuracy: 0.4512 - val_loss: 1.9847 - val_accuracy: 0.4668\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 2.0639 - accuracy: 0.4506 - val_loss: 1.9753 - val_accuracy: 0.4746\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 2.0485 - accuracy: 0.4538 - val_loss: 1.9540 - val_accuracy: 0.4771\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 2.0514 - accuracy: 0.4524 - val_loss: 1.9575 - val_accuracy: 0.4802\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 2.0425 - accuracy: 0.4542 - val_loss: 1.9523 - val_accuracy: 0.4780\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 2.0380 - accuracy: 0.4522 - val_loss: 1.9387 - val_accuracy: 0.4821\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 2.0284 - accuracy: 0.4551 - val_loss: 1.9420 - val_accuracy: 0.4810\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 2.0235 - accuracy: 0.4583 - val_loss: 1.9646 - val_accuracy: 0.4774\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 2.0196 - accuracy: 0.4604 - val_loss: 1.9418 - val_accuracy: 0.4781\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 2.0069 - accuracy: 0.4626 - val_loss: 1.9477 - val_accuracy: 0.4862\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 2.0059 - accuracy: 0.4648 - val_loss: 1.9355 - val_accuracy: 0.4809\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 1.9963 - accuracy: 0.4614 - val_loss: 1.9164 - val_accuracy: 0.4904\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 1.9879 - accuracy: 0.4676 - val_loss: 1.9560 - val_accuracy: 0.4808\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.9825 - accuracy: 0.4665 - val_loss: 1.9054 - val_accuracy: 0.4912\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.9881 - accuracy: 0.4672 - val_loss: 1.9387 - val_accuracy: 0.4841\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.9694 - accuracy: 0.4706 - val_loss: 1.9070 - val_accuracy: 0.4896\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.9624 - accuracy: 0.4686 - val_loss: 1.8919 - val_accuracy: 0.4950\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.9606 - accuracy: 0.4714 - val_loss: 1.9167 - val_accuracy: 0.4870\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.9566 - accuracy: 0.4730 - val_loss: 1.8918 - val_accuracy: 0.4973\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.9516 - accuracy: 0.4725 - val_loss: 1.8921 - val_accuracy: 0.4921\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.9523 - accuracy: 0.4756 - val_loss: 1.9037 - val_accuracy: 0.4881\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.9412 - accuracy: 0.4751 - val_loss: 1.9085 - val_accuracy: 0.4854\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.9338 - accuracy: 0.4785 - val_loss: 1.9014 - val_accuracy: 0.4970\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.9262 - accuracy: 0.4799 - val_loss: 1.9006 - val_accuracy: 0.4886\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 24s 16ms/step - loss: 1.9252 - accuracy: 0.4806 - val_loss: 1.8706 - val_accuracy: 0.4990\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 1.9171 - accuracy: 0.4803 - val_loss: 1.8758 - val_accuracy: 0.4959\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 1.9239 - accuracy: 0.4773 - val_loss: 1.8825 - val_accuracy: 0.4955\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.9098 - accuracy: 0.4835 - val_loss: 1.8823 - val_accuracy: 0.4962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21230fe5820>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=32,epochs=30,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74ca1f92-ca8c-4d74-a9c1-1515e38a97e7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.9070 - accuracy: 0.4835 - val_loss: 1.8719 - val_accuracy: 0.4963\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.9058 - accuracy: 0.4848 - val_loss: 1.8619 - val_accuracy: 0.4974\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.9043 - accuracy: 0.4840 - val_loss: 1.8837 - val_accuracy: 0.4975\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8987 - accuracy: 0.4819 - val_loss: 1.8678 - val_accuracy: 0.5003\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8966 - accuracy: 0.4841 - val_loss: 1.8499 - val_accuracy: 0.5060\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8837 - accuracy: 0.4886 - val_loss: 1.8619 - val_accuracy: 0.5009\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8914 - accuracy: 0.4874 - val_loss: 1.8714 - val_accuracy: 0.4997\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8949 - accuracy: 0.4866 - val_loss: 1.8623 - val_accuracy: 0.4978\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8724 - accuracy: 0.4924 - val_loss: 1.8610 - val_accuracy: 0.4982\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8726 - accuracy: 0.4924 - val_loss: 1.8409 - val_accuracy: 0.5059\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8735 - accuracy: 0.4906 - val_loss: 1.8477 - val_accuracy: 0.5072\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8694 - accuracy: 0.4911 - val_loss: 1.8507 - val_accuracy: 0.5026\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8643 - accuracy: 0.4926 - val_loss: 1.8744 - val_accuracy: 0.4992\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8537 - accuracy: 0.4966 - val_loss: 1.8733 - val_accuracy: 0.4981\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8664 - accuracy: 0.4923 - val_loss: 1.8738 - val_accuracy: 0.5016\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8575 - accuracy: 0.4922 - val_loss: 1.8568 - val_accuracy: 0.5012\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8619 - accuracy: 0.4931 - val_loss: 1.8732 - val_accuracy: 0.4996\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8560 - accuracy: 0.4939 - val_loss: 1.8353 - val_accuracy: 0.5069\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8469 - accuracy: 0.5007 - val_loss: 1.8348 - val_accuracy: 0.5043\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8490 - accuracy: 0.4957 - val_loss: 1.8290 - val_accuracy: 0.5083\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8405 - accuracy: 0.4975 - val_loss: 1.8483 - val_accuracy: 0.5054\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8490 - accuracy: 0.4980 - val_loss: 1.8445 - val_accuracy: 0.5054\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8393 - accuracy: 0.5015 - val_loss: 1.8297 - val_accuracy: 0.5069\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8407 - accuracy: 0.4974 - val_loss: 1.8238 - val_accuracy: 0.5065\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8358 - accuracy: 0.5008 - val_loss: 1.8402 - val_accuracy: 0.5055\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8375 - accuracy: 0.4997 - val_loss: 1.8477 - val_accuracy: 0.5026\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8239 - accuracy: 0.5010 - val_loss: 1.8344 - val_accuracy: 0.5084\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8241 - accuracy: 0.5018 - val_loss: 1.8513 - val_accuracy: 0.5062\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8220 - accuracy: 0.5041 - val_loss: 1.8290 - val_accuracy: 0.5120\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8247 - accuracy: 0.5019 - val_loss: 1.8306 - val_accuracy: 0.5094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x212326a3760>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('CIFAR100_2.h5')\n",
    "model.fit(x_train,y_train,batch_size=32,epochs=30,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2c99b97-6b99-43a3-a345-c31d5235d1b0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8308 - accuracy: 0.4985 - val_loss: 1.8766 - val_accuracy: 0.5007\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8169 - accuracy: 0.5021 - val_loss: 1.8336 - val_accuracy: 0.5061\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8208 - accuracy: 0.5023 - val_loss: 1.8344 - val_accuracy: 0.5094\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8174 - accuracy: 0.5047 - val_loss: 1.8169 - val_accuracy: 0.5136\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8048 - accuracy: 0.5084 - val_loss: 1.8377 - val_accuracy: 0.5066\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8103 - accuracy: 0.5043 - val_loss: 1.8161 - val_accuracy: 0.5090\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8026 - accuracy: 0.5082 - val_loss: 1.8223 - val_accuracy: 0.5145\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7971 - accuracy: 0.5043 - val_loss: 1.8110 - val_accuracy: 0.5091\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8034 - accuracy: 0.5056 - val_loss: 1.8295 - val_accuracy: 0.5097\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.8082 - accuracy: 0.5025 - val_loss: 1.8335 - val_accuracy: 0.5085\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7992 - accuracy: 0.5074 - val_loss: 1.8113 - val_accuracy: 0.5136\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7956 - accuracy: 0.5065 - val_loss: 1.8226 - val_accuracy: 0.5146\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7909 - accuracy: 0.5091 - val_loss: 1.8128 - val_accuracy: 0.5129\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7971 - accuracy: 0.5080 - val_loss: 1.8070 - val_accuracy: 0.5154\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7972 - accuracy: 0.5102 - val_loss: 1.8201 - val_accuracy: 0.5119\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7858 - accuracy: 0.5093 - val_loss: 1.8249 - val_accuracy: 0.5064\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7871 - accuracy: 0.5095 - val_loss: 1.7992 - val_accuracy: 0.5132\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7877 - accuracy: 0.5088 - val_loss: 1.8193 - val_accuracy: 0.5098\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7780 - accuracy: 0.5121 - val_loss: 1.8183 - val_accuracy: 0.5122\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7805 - accuracy: 0.5122 - val_loss: 1.7993 - val_accuracy: 0.5109\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7825 - accuracy: 0.5128 - val_loss: 1.8089 - val_accuracy: 0.5140\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7844 - accuracy: 0.5111 - val_loss: 1.8131 - val_accuracy: 0.5118\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7823 - accuracy: 0.5115 - val_loss: 1.8180 - val_accuracy: 0.5092\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7735 - accuracy: 0.5158 - val_loss: 1.7989 - val_accuracy: 0.5124\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7708 - accuracy: 0.5130 - val_loss: 1.8366 - val_accuracy: 0.5066\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7627 - accuracy: 0.5155 - val_loss: 1.8181 - val_accuracy: 0.5114\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7664 - accuracy: 0.5140 - val_loss: 1.8138 - val_accuracy: 0.5133\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7643 - accuracy: 0.5175 - val_loss: 1.8127 - val_accuracy: 0.5146\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7644 - accuracy: 0.5134 - val_loss: 1.8527 - val_accuracy: 0.5056\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7619 - accuracy: 0.5170 - val_loss: 1.8790 - val_accuracy: 0.4997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21233072a30>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('CIFAR100_3.h5')\n",
    "model.fit(x_train,y_train,batch_size=32,epochs=30,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92db06b4-390e-4365-b56e-cb8e32a821ef",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7630 - accuracy: 0.5160 - val_loss: 1.7889 - val_accuracy: 0.5164\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7624 - accuracy: 0.5156 - val_loss: 1.8045 - val_accuracy: 0.5145\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7591 - accuracy: 0.5182 - val_loss: 1.8070 - val_accuracy: 0.5202\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7503 - accuracy: 0.5180 - val_loss: 1.7918 - val_accuracy: 0.5217\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7432 - accuracy: 0.5200 - val_loss: 1.8079 - val_accuracy: 0.5141\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7536 - accuracy: 0.5201 - val_loss: 1.7884 - val_accuracy: 0.5177\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7481 - accuracy: 0.5168 - val_loss: 1.8080 - val_accuracy: 0.5115\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7471 - accuracy: 0.5168 - val_loss: 1.8201 - val_accuracy: 0.5148\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7453 - accuracy: 0.5204 - val_loss: 1.8124 - val_accuracy: 0.5154\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7430 - accuracy: 0.5197 - val_loss: 1.7883 - val_accuracy: 0.5216\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7436 - accuracy: 0.5202 - val_loss: 1.7946 - val_accuracy: 0.5205\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7422 - accuracy: 0.5199 - val_loss: 1.7907 - val_accuracy: 0.5209\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7456 - accuracy: 0.5175 - val_loss: 1.8062 - val_accuracy: 0.5148\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7310 - accuracy: 0.5223 - val_loss: 1.7985 - val_accuracy: 0.5182\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7436 - accuracy: 0.5195 - val_loss: 1.7925 - val_accuracy: 0.5173\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7301 - accuracy: 0.5235 - val_loss: 1.8148 - val_accuracy: 0.5120\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7376 - accuracy: 0.5208 - val_loss: 1.8186 - val_accuracy: 0.5118\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7371 - accuracy: 0.5219 - val_loss: 1.8021 - val_accuracy: 0.5189\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7442 - accuracy: 0.5194 - val_loss: 1.7903 - val_accuracy: 0.5195\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7327 - accuracy: 0.5229 - val_loss: 1.8159 - val_accuracy: 0.5121\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7282 - accuracy: 0.5238 - val_loss: 1.7875 - val_accuracy: 0.5192\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7349 - accuracy: 0.5220 - val_loss: 1.8067 - val_accuracy: 0.5179\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7214 - accuracy: 0.5242 - val_loss: 1.7915 - val_accuracy: 0.5210\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7268 - accuracy: 0.5241 - val_loss: 1.8015 - val_accuracy: 0.5142\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7251 - accuracy: 0.5230 - val_loss: 1.7862 - val_accuracy: 0.5204\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7292 - accuracy: 0.5233 - val_loss: 1.8131 - val_accuracy: 0.5158\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7179 - accuracy: 0.5249 - val_loss: 1.8113 - val_accuracy: 0.5140\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7295 - accuracy: 0.5225 - val_loss: 1.7803 - val_accuracy: 0.5231\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7232 - accuracy: 0.5214 - val_loss: 1.8081 - val_accuracy: 0.5140\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7220 - accuracy: 0.5261 - val_loss: 1.8112 - val_accuracy: 0.5161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2123245fa60>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('CIFAR100_4.h5')\n",
    "model.fit(x_train,y_train,batch_size=32,epochs=30,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "112bd8fd-d834-47a6-b4bd-c51bdfb4b677",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.6906 - accuracy: 0.5282 - val_loss: 1.7882 - val_accuracy: 0.5244\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6899 - accuracy: 0.5323 - val_loss: 1.7602 - val_accuracy: 0.5259\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6865 - accuracy: 0.5315 - val_loss: 1.7778 - val_accuracy: 0.5271\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6897 - accuracy: 0.5316 - val_loss: 1.7821 - val_accuracy: 0.5240\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6810 - accuracy: 0.5345 - val_loss: 1.7686 - val_accuracy: 0.5260\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6839 - accuracy: 0.5336 - val_loss: 1.7902 - val_accuracy: 0.5210\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6629 - accuracy: 0.5371 - val_loss: 1.7709 - val_accuracy: 0.5266\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6899 - accuracy: 0.5328 - val_loss: 1.7928 - val_accuracy: 0.5232\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6796 - accuracy: 0.5340 - val_loss: 1.7796 - val_accuracy: 0.5269\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6790 - accuracy: 0.5328 - val_loss: 1.7786 - val_accuracy: 0.5244\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6785 - accuracy: 0.5317 - val_loss: 1.7744 - val_accuracy: 0.5283\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6787 - accuracy: 0.5341 - val_loss: 1.7750 - val_accuracy: 0.5235\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6751 - accuracy: 0.5356 - val_loss: 1.7750 - val_accuracy: 0.5266\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6723 - accuracy: 0.5349 - val_loss: 1.7741 - val_accuracy: 0.5267\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6798 - accuracy: 0.5340 - val_loss: 1.7877 - val_accuracy: 0.5240\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6764 - accuracy: 0.5336 - val_loss: 1.7768 - val_accuracy: 0.5274\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6747 - accuracy: 0.5367 - val_loss: 1.7821 - val_accuracy: 0.5223\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6762 - accuracy: 0.5365 - val_loss: 1.7872 - val_accuracy: 0.5248\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6673 - accuracy: 0.5338 - val_loss: 1.7842 - val_accuracy: 0.5213\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6745 - accuracy: 0.5361 - val_loss: 1.7870 - val_accuracy: 0.5242\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6662 - accuracy: 0.5355 - val_loss: 1.7837 - val_accuracy: 0.5200\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6762 - accuracy: 0.5346 - val_loss: 1.7918 - val_accuracy: 0.5241\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6715 - accuracy: 0.5357 - val_loss: 1.7806 - val_accuracy: 0.5254\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 1.6595 - accuracy: 0.5376 - val_loss: 1.7997 - val_accuracy: 0.5213\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 1.6715 - accuracy: 0.5361 - val_loss: 1.7778 - val_accuracy: 0.5242\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6694 - accuracy: 0.5362 - val_loss: 1.7777 - val_accuracy: 0.5229\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6619 - accuracy: 0.5383 - val_loss: 1.7808 - val_accuracy: 0.5255\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.6662 - accuracy: 0.5348 - val_loss: 1.7691 - val_accuracy: 0.5255\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6615 - accuracy: 0.5368 - val_loss: 1.7644 - val_accuracy: 0.5263\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6779 - accuracy: 0.5347 - val_loss: 1.7622 - val_accuracy: 0.5308\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6634 - accuracy: 0.5345 - val_loss: 1.7927 - val_accuracy: 0.5209\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6683 - accuracy: 0.5352 - val_loss: 1.7661 - val_accuracy: 0.5293\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6631 - accuracy: 0.5383 - val_loss: 1.7828 - val_accuracy: 0.5292\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6667 - accuracy: 0.5371 - val_loss: 1.7722 - val_accuracy: 0.5263\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6582 - accuracy: 0.5411 - val_loss: 1.7831 - val_accuracy: 0.5280\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6607 - accuracy: 0.5374 - val_loss: 1.7878 - val_accuracy: 0.5219\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6533 - accuracy: 0.5399 - val_loss: 1.7713 - val_accuracy: 0.5269\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6562 - accuracy: 0.5401 - val_loss: 1.7689 - val_accuracy: 0.5278\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6571 - accuracy: 0.5376 - val_loss: 1.7734 - val_accuracy: 0.5267\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6634 - accuracy: 0.5376 - val_loss: 1.7700 - val_accuracy: 0.5316\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6642 - accuracy: 0.5396 - val_loss: 1.7712 - val_accuracy: 0.5293\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6560 - accuracy: 0.5378 - val_loss: 1.7637 - val_accuracy: 0.5311\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6478 - accuracy: 0.5409 - val_loss: 1.7629 - val_accuracy: 0.5308\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6574 - accuracy: 0.5384 - val_loss: 1.7643 - val_accuracy: 0.5299\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6501 - accuracy: 0.5396 - val_loss: 1.7791 - val_accuracy: 0.5260\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6548 - accuracy: 0.5380 - val_loss: 1.7710 - val_accuracy: 0.5304\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6584 - accuracy: 0.5396 - val_loss: 1.7942 - val_accuracy: 0.5242\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6526 - accuracy: 0.5403 - val_loss: 1.7777 - val_accuracy: 0.5301\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6565 - accuracy: 0.5389 - val_loss: 1.7816 - val_accuracy: 0.5327\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6541 - accuracy: 0.5406 - val_loss: 1.7703 - val_accuracy: 0.5336\n",
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6581 - accuracy: 0.5388 - val_loss: 1.7872 - val_accuracy: 0.5253\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6495 - accuracy: 0.5437 - val_loss: 1.7595 - val_accuracy: 0.5342\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6431 - accuracy: 0.5409 - val_loss: 1.7884 - val_accuracy: 0.5300\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6468 - accuracy: 0.5412 - val_loss: 1.7571 - val_accuracy: 0.5346\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6543 - accuracy: 0.5385 - val_loss: 1.7719 - val_accuracy: 0.5335\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6542 - accuracy: 0.5394 - val_loss: 1.7688 - val_accuracy: 0.5312\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6492 - accuracy: 0.5415 - val_loss: 1.7644 - val_accuracy: 0.5325\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6470 - accuracy: 0.5420 - val_loss: 1.7743 - val_accuracy: 0.5304\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6415 - accuracy: 0.5415 - val_loss: 1.7625 - val_accuracy: 0.5346\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6431 - accuracy: 0.5408 - val_loss: 1.7670 - val_accuracy: 0.5256\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6456 - accuracy: 0.5413 - val_loss: 1.7595 - val_accuracy: 0.5325\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6401 - accuracy: 0.5425 - val_loss: 1.7603 - val_accuracy: 0.5324\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6436 - accuracy: 0.5403 - val_loss: 1.7708 - val_accuracy: 0.5333\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6410 - accuracy: 0.5432 - val_loss: 1.7527 - val_accuracy: 0.5321\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6341 - accuracy: 0.5442 - val_loss: 1.7587 - val_accuracy: 0.5318\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 1.6395 - accuracy: 0.5428 - val_loss: 1.7499 - val_accuracy: 0.5330\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 1.6374 - accuracy: 0.5441 - val_loss: 1.7601 - val_accuracy: 0.5291\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6378 - accuracy: 0.5442 - val_loss: 1.7743 - val_accuracy: 0.5285\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6390 - accuracy: 0.5430 - val_loss: 1.7859 - val_accuracy: 0.5245\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6355 - accuracy: 0.5420 - val_loss: 1.7658 - val_accuracy: 0.5309\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6376 - accuracy: 0.5476 - val_loss: 1.7735 - val_accuracy: 0.5240\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6314 - accuracy: 0.5465 - val_loss: 1.7470 - val_accuracy: 0.5327\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6304 - accuracy: 0.5458 - val_loss: 1.7667 - val_accuracy: 0.5316\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6404 - accuracy: 0.5403 - val_loss: 1.7654 - val_accuracy: 0.5306\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6416 - accuracy: 0.5424 - val_loss: 1.7532 - val_accuracy: 0.5316\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6410 - accuracy: 0.5429 - val_loss: 1.7495 - val_accuracy: 0.5351\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6343 - accuracy: 0.5469 - val_loss: 1.7755 - val_accuracy: 0.5266\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6386 - accuracy: 0.5416 - val_loss: 1.7596 - val_accuracy: 0.5332\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6340 - accuracy: 0.5440 - val_loss: 1.7849 - val_accuracy: 0.5287\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6353 - accuracy: 0.5435 - val_loss: 1.7610 - val_accuracy: 0.5313\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6287 - accuracy: 0.5448 - val_loss: 1.7681 - val_accuracy: 0.5330\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6296 - accuracy: 0.5457 - val_loss: 1.7557 - val_accuracy: 0.5301\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6318 - accuracy: 0.5451 - val_loss: 1.7673 - val_accuracy: 0.5295\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6337 - accuracy: 0.5422 - val_loss: 1.7504 - val_accuracy: 0.5372\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 1.6335 - accuracy: 0.5434 - val_loss: 1.7664 - val_accuracy: 0.5288\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6231 - accuracy: 0.5454 - val_loss: 1.7698 - val_accuracy: 0.5354\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6319 - accuracy: 0.5455 - val_loss: 1.7612 - val_accuracy: 0.5297\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6340 - accuracy: 0.5445 - val_loss: 1.7667 - val_accuracy: 0.5313\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6213 - accuracy: 0.5463 - val_loss: 1.7594 - val_accuracy: 0.5325\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 1.6214 - accuracy: 0.5473 - val_loss: 1.7706 - val_accuracy: 0.5326\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6268 - accuracy: 0.5450 - val_loss: 1.7573 - val_accuracy: 0.5357\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 1.6278 - accuracy: 0.5441 - val_loss: 1.7775 - val_accuracy: 0.5329\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6370 - accuracy: 0.5429 - val_loss: 1.7628 - val_accuracy: 0.5304\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6253 - accuracy: 0.5471 - val_loss: 1.7597 - val_accuracy: 0.5329\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 1.6196 - accuracy: 0.5457 - val_loss: 1.7870 - val_accuracy: 0.5277\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 1.6264 - accuracy: 0.5447 - val_loss: 1.7573 - val_accuracy: 0.5348\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6205 - accuracy: 0.5426 - val_loss: 1.7712 - val_accuracy: 0.5329\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6306 - accuracy: 0.5440 - val_loss: 1.7839 - val_accuracy: 0.5258\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6253 - accuracy: 0.5471 - val_loss: 1.7603 - val_accuracy: 0.5316\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 1.6219 - accuracy: 0.5477 - val_loss: 1.7664 - val_accuracy: 0.5343\n",
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6171 - accuracy: 0.5478 - val_loss: 1.7689 - val_accuracy: 0.5308\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6194 - accuracy: 0.5477 - val_loss: 1.7609 - val_accuracy: 0.5332\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6206 - accuracy: 0.5461 - val_loss: 1.7808 - val_accuracy: 0.5327\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6158 - accuracy: 0.5492 - val_loss: 1.7607 - val_accuracy: 0.5364\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6272 - accuracy: 0.5430 - val_loss: 1.7625 - val_accuracy: 0.5308\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6210 - accuracy: 0.5471 - val_loss: 1.7611 - val_accuracy: 0.5335\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6233 - accuracy: 0.5484 - val_loss: 1.7781 - val_accuracy: 0.5279\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6073 - accuracy: 0.5498 - val_loss: 1.7650 - val_accuracy: 0.5332\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6271 - accuracy: 0.5474 - val_loss: 1.7549 - val_accuracy: 0.5304\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6170 - accuracy: 0.5493 - val_loss: 1.7460 - val_accuracy: 0.5386\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6159 - accuracy: 0.5470 - val_loss: 1.7486 - val_accuracy: 0.5334\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6139 - accuracy: 0.5497 - val_loss: 1.7720 - val_accuracy: 0.5325\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6104 - accuracy: 0.5504 - val_loss: 1.7626 - val_accuracy: 0.5335\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6207 - accuracy: 0.5489 - val_loss: 1.7461 - val_accuracy: 0.5379\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6213 - accuracy: 0.5483 - val_loss: 1.7711 - val_accuracy: 0.5337\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6136 - accuracy: 0.5495 - val_loss: 1.7642 - val_accuracy: 0.5346\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6103 - accuracy: 0.5492 - val_loss: 1.7637 - val_accuracy: 0.5306\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 1.6195 - accuracy: 0.5482 - val_loss: 1.7509 - val_accuracy: 0.5351\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6044 - accuracy: 0.5517 - val_loss: 1.7677 - val_accuracy: 0.5287\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6119 - accuracy: 0.5470 - val_loss: 1.7574 - val_accuracy: 0.5350\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6149 - accuracy: 0.5476 - val_loss: 1.7544 - val_accuracy: 0.5322\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6079 - accuracy: 0.5498 - val_loss: 1.7692 - val_accuracy: 0.5297\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6119 - accuracy: 0.5495 - val_loss: 1.7667 - val_accuracy: 0.5317\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6122 - accuracy: 0.5498 - val_loss: 1.7628 - val_accuracy: 0.5351\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6173 - accuracy: 0.5451 - val_loss: 1.7868 - val_accuracy: 0.5258\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6076 - accuracy: 0.5509 - val_loss: 1.7679 - val_accuracy: 0.5326\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6114 - accuracy: 0.5516 - val_loss: 1.7547 - val_accuracy: 0.5336\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6083 - accuracy: 0.5480 - val_loss: 1.7651 - val_accuracy: 0.5315\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6073 - accuracy: 0.5492 - val_loss: 1.7588 - val_accuracy: 0.5314\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6133 - accuracy: 0.5508 - val_loss: 1.7586 - val_accuracy: 0.5314\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6101 - accuracy: 0.5494 - val_loss: 1.7491 - val_accuracy: 0.5356\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6091 - accuracy: 0.5511 - val_loss: 1.7493 - val_accuracy: 0.5346\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6052 - accuracy: 0.5494 - val_loss: 1.7631 - val_accuracy: 0.5363\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6111 - accuracy: 0.5481 - val_loss: 1.7411 - val_accuracy: 0.5378\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.5976 - accuracy: 0.5533 - val_loss: 1.7598 - val_accuracy: 0.5356\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6122 - accuracy: 0.5471 - val_loss: 1.7771 - val_accuracy: 0.5287\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6063 - accuracy: 0.5521 - val_loss: 1.7485 - val_accuracy: 0.5393\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6103 - accuracy: 0.5502 - val_loss: 1.7774 - val_accuracy: 0.5279\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6027 - accuracy: 0.5506 - val_loss: 1.7505 - val_accuracy: 0.5335\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6002 - accuracy: 0.5535 - val_loss: 1.7596 - val_accuracy: 0.5287\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6049 - accuracy: 0.5542 - val_loss: 1.7641 - val_accuracy: 0.5312\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.5980 - accuracy: 0.5542 - val_loss: 1.7629 - val_accuracy: 0.5302\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6076 - accuracy: 0.5497 - val_loss: 1.7690 - val_accuracy: 0.5361\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 1.5994 - accuracy: 0.5504 - val_loss: 1.7686 - val_accuracy: 0.5312\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.5940 - accuracy: 0.5543 - val_loss: 1.7624 - val_accuracy: 0.5331\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6059 - accuracy: 0.5500 - val_loss: 1.7662 - val_accuracy: 0.5300\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.5923 - accuracy: 0.5530 - val_loss: 1.7465 - val_accuracy: 0.5350\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6117 - accuracy: 0.5487 - val_loss: 1.7443 - val_accuracy: 0.5362\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.5981 - accuracy: 0.5512 - val_loss: 1.7519 - val_accuracy: 0.5358\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.5994 - accuracy: 0.5512 - val_loss: 1.7772 - val_accuracy: 0.5290\n",
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.5972 - accuracy: 0.5539 - val_loss: 1.7585 - val_accuracy: 0.5326\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6010 - accuracy: 0.5493 - val_loss: 1.7446 - val_accuracy: 0.5337\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6041 - accuracy: 0.5529 - val_loss: 1.7839 - val_accuracy: 0.5257\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.6013 - accuracy: 0.5517 - val_loss: 1.7524 - val_accuracy: 0.5346\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.6012 - accuracy: 0.5496 - val_loss: 1.7450 - val_accuracy: 0.5323\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.5920 - accuracy: 0.5531 - val_loss: 1.7570 - val_accuracy: 0.5348\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 1.5957 - accuracy: 0.5528 - val_loss: 1.7535 - val_accuracy: 0.5359\n",
      "Epoch 8/50\n",
      "  45/1563 [..............................] - ETA: 21s - loss: 1.5501 - accuracy: 0.5778"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m      2\u001b[0m     model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCIFAR100_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(5,10):\n",
    "    model.save('CIFAR100_'+str(i)+'.h5')\n",
    "    model.fit(x_train,y_train,batch_size=32,epochs=50,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e8398e5-a487-44fc-98a1-d3315fa96748",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('CIFAR100_stopAdam.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3816a696-159b-43ae-a6c4-87f21dc650b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.optimizers.Adadelta(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "046c3432-7e18-490b-88fe-7fdb8bce1018",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 22s 13ms/step - loss: 1.5624 - accuracy: 0.5583 - val_loss: 1.7325 - val_accuracy: 0.5393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e841efe610>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"CIFAR100_test1.h5\")\n",
    "model.save('CIFAR100_test2.h5')\n",
    "model.fit(x_train,y_train,batch_size=32,epochs=1,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0e63af-210f-4682-abd2-47acecf83a25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.5586 - accuracy: 0.5607 - val_loss: 1.7324 - val_accuracy: 0.5392\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.5592 - accuracy: 0.5608 - val_loss: 1.7322 - val_accuracy: 0.5405\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.5515 - accuracy: 0.5617 - val_loss: 1.7328 - val_accuracy: 0.5395\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.5582 - accuracy: 0.5617 - val_loss: 1.7323 - val_accuracy: 0.5388\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.5603 - accuracy: 0.5612 - val_loss: 1.7302 - val_accuracy: 0.5400\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.5618 - accuracy: 0.5599 - val_loss: 1.7298 - val_accuracy: 0.5392\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 1.5471 - accuracy: 0.5616 - val_loss: 1.7318 - val_accuracy: 0.5385\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.5506 - accuracy: 0.5609 - val_loss: 1.7334 - val_accuracy: 0.5388\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.5573 - accuracy: 0.5614 - val_loss: 1.7305 - val_accuracy: 0.5389\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.5523 - accuracy: 0.5609 - val_loss: 1.7333 - val_accuracy: 0.5382\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.5611 - accuracy: 0.5617 - val_loss: 1.7296 - val_accuracy: 0.5391\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.5490 - accuracy: 0.5625 - val_loss: 1.7302 - val_accuracy: 0.5392\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.5557 - accuracy: 0.5629 - val_loss: 1.7344 - val_accuracy: 0.5379\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.5583 - accuracy: 0.5617 - val_loss: 1.7296 - val_accuracy: 0.5381\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.5538 - accuracy: 0.5647 - val_loss: 1.7313 - val_accuracy: 0.5390\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.5521 - accuracy: 0.5625 - val_loss: 1.7323 - val_accuracy: 0.5399\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.5522 - accuracy: 0.5615 - val_loss: 1.7308 - val_accuracy: 0.5401\n",
      "Epoch 18/50\n",
      "1220/1563 [======================>.......] - ETA: 4s - loss: 1.5519 - accuracy: 0.5605"
     ]
    }
   ],
   "source": [
    "for i in range(11,15):\n",
    "    model.save('CIFAR100_'+str(i)+'.h5')\n",
    "    model.fit(x_train,y_train,batch_size=32,epochs=50,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6186a282-2204-4b0e-8bd2-c08bd411cf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.0398 - accuracy: 0.9875 - 1s/epoch - 3ms/step\n",
      "[0.039796166121959686, 0.987500011920929]\n",
      "8440\n",
      "(28, 28, 3)\n",
      "(28, 28, 1)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results=model.evaluate(x_test,y_test,batch_size=32,verbose=2)\n",
    "print(str(results))\n",
    "value=np.random.randint(0,10000)\n",
    "print(value)\n",
    "for id in range(len(y_train)):\n",
    "    #print(labels[id])\n",
    "    #break\n",
    "    #22 - M big\n",
    "    if(y_train.argmax()==7):\n",
    "        value=id\n",
    "        break\n",
    "        \n",
    "\n",
    "\n",
    "#print(x_train[value].shape)\n",
    "\n",
    "single=x_train[value]\n",
    "image=np.zeros((28,28,3))\n",
    "print(image.shape)\n",
    "\n",
    "for y in range(0,image.shape[0]):\n",
    "    for x in range(0,image.shape[1]):\n",
    "        for c in range(0,image.shape[2]):\n",
    "            image[y,x,c]=single[y][x]\n",
    "\n",
    "\n",
    "\n",
    "print(single.shape)\n",
    "#print(single)\n",
    "\n",
    "singleReady=np.zeros((1,28,28))\n",
    "\n",
    "for y in range(0,image.shape[0]):\n",
    "    for x in range(0,image.shape[1]):\n",
    "            singleReady[0][y][x]=single[y][x]\n",
    "\n",
    "print(model.predict(singleReady,batch_size=1).argmax())\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d90177ee-7111-49bd-87de-fd4323a5947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_model_CNN/CIFAR100_byclass_done.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28f6ad4b-c994-4c6b-9412-9b84fa1e51c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results=model.evaluate(x_test,y_test,batch_size=32,verbose=2)\n",
    "#print(str(results))\n",
    "#value=np.random.randint(0,10000)\n",
    "\n",
    "id=22\n",
    "for v in y_train:\n",
    "    if(v.argmax()==id):\n",
    "        print(id)\n",
    "        ShowImage(v)\n",
    "        break\n",
    "        #id+=1\n",
    "currentIteration=0\n",
    "'''for v in y_train:\n",
    "    if(v==id):\n",
    "        print(id,v)\n",
    "        ShowImage(v)\n",
    "        currentIteration+=1\n",
    "        id+=1    \n",
    "    if(currentIteration==10):\n",
    "        break'''\n",
    "\n",
    "\n",
    "def ShowImage(value:int):\n",
    "    print(x_train[value].shape)\n",
    "\n",
    "    single=x_train[value]\n",
    "    image=np.zeros((28,28,3))\n",
    "    print(image.shape)\n",
    "\n",
    "    for y in range(0,image.shape[0]):\n",
    "        for x in range(0,image.shape[1]):\n",
    "            for c in range(0,image.shape[2]):\n",
    "                image[y,x,c]=single[y*28+x]\n",
    "\n",
    "\n",
    "\n",
    "    #print(single.shape)\n",
    "    #print(single)\n",
    "\n",
    "    #singleReady=np.zeros((1,28*28))\n",
    "\n",
    "    #for y in range(0,image.shape[0]):\n",
    "    #    for x in range(0,image.shape[1]):\n",
    "    #            singleReady[0][y*28+x]=single[y*28+x]\n",
    "\n",
    "    #print(model.predict(singleReady,batch_size=1).argmax())\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86d82074-35d5-4ed4-842c-8f9e6e7a81ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "IMG = np.asarray(Image.open('E:/JupyterLab/Tensorflow_FKI_fall_2022/2022.10.07/Segmented/9.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95b55033-6874-4064-a576-4b032543f4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n",
      "(1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(IMG)\n",
    "plt.show()\n",
    "print(IMG.shape)\n",
    "\n",
    "IMG_2=np.zeros((1,28,28),dtype=\"float32\")\n",
    "\n",
    "for x in range(28):\n",
    "    for y in range(28):\n",
    "        IMG_2[0][x][y]=IMG[x][y][0]/255.\n",
    "print(IMG_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c89da332-81e7-4a97-81fd-01a53ed022a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(IMG_2,batch_size=1).argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4873c98d-4e6f-4e4a-a4f8-74653017b9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
