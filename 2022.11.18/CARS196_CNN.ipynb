{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce3ea746-73ef-48d5-aa6c-ab067a72e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "#Используем костыль для исправления IntelliSense для keras по гайду:\n",
    "#https://stackoverflow.com/questions/71000250/import-tensorflow-keras-could-not-be-resolved-after-upgrading-to-tensorflow-2\n",
    "import keras.api._v2.keras as keras\n",
    "from keras import layers\n",
    "from keras import losses\n",
    "#from keras.datasets import CIFAR100\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "304f1488-0e88-4946-be80-7b046e3fbb6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassLabel(shape=(), dtype=tf.int64, num_classes=196)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_classes=196\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'cars196',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "print(ds_info.features['label'])\n",
    "def prepare_img(image, label):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    #output = tf.image.crop_and_resize(image, boxes, box_indices, CROP_SIZE)\n",
    "    \n",
    "    image2=tf.image.central_crop(image,1)\n",
    "    image3=tf.image.resize(image2,[32,32])\n",
    "    #image4=tf.image.no\n",
    "    #image4=tf.image.rgb_to_grayscale(image3)\n",
    "    #label = keras.utils.to_categorical(label, num_classes)\n",
    "    return tf.cast(image3, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(prepare_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.map(prepare_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "#ds_train = ds_train.cache(\"ds_train\")\n",
    "#ds_test = ds_train.cache(\"ds_test\")\n",
    "\n",
    "#ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(1000)\n",
    "ds_test=ds_test.batch(1000)\n",
    "for image,label in ds_train:\n",
    "    #print(label)\n",
    "    #print()\n",
    "    #print(image)\n",
    "    plt.imshow(image[0].reshape((32,32,3)), interpolation='nearest')\n",
    "    plt.show()\n",
    "    break\n",
    "#ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "#print(ds_train.)\n",
    "#dataset = tf.data.Dataset.from_generator(get_image, output_shapes=(128, 128), output_types=(tf.float32))\n",
    "#print(prepare_img())\n",
    "\n",
    "#tf.image.crop_and_resize\n",
    "#tf.image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b69d7948-26fb-454c-8257-28ada65466f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#num_classes=100\n",
    "#input_shape = (32, 32, 1)\n",
    "input_shape = (32, 32, 3)\n",
    "#x_train = np.expand_dims(x_train, -1)\n",
    "#x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "#print(\"Train X=%s, y=%s\"%(x_train.shape,y_train.shape))\n",
    "#print(\"Train Letters X=%s, y=%s\"%(x_train_l.shape,y_train_l.shape))\n",
    "#print(\"Test X=%s, y=%s\"%(x_test1.shape,y_test.shape))\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Train X=%s, y=%s\"%(x_train.shape,y_train.shape))\n",
    "#print(\"Test X=%s, y=%s\"%(x_test.shape,y_test.shape))\n",
    "#print(x_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4415ec0d-cc5a-4cab-b2ff-27ea927c103f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 196)\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_60 (Bat  (None, 32, 32, 3)        12        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 28, 28, 32)        2432      \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 14, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_61 (Bat  (None, 14, 14, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 12, 12, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_62 (Bat  (None, 12, 12, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 10, 10, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_63 (Bat  (None, 10, 10, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 3200)              0         \n",
      "                                                                 \n",
      " batch_normalization_64 (Bat  (None, 3200)             12800     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 196)               627396    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 661,520\n",
      "Trainable params: 654,922\n",
      "Non-trainable params: 6,598\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\",use_bias=True),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.BatchNormalization(),\n",
    "        #layers.Dropout(0.2),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\",use_bias=True),\n",
    "        layers.BatchNormalization(),\n",
    "        #layers.Dropout(0.2),\n",
    "        #layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\",use_bias=True),\n",
    "        layers.BatchNormalization(),\n",
    "        #layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.BatchNormalization(),\n",
    "        #layers.Dropout(0.4),\n",
    "        #layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]#52 Буквы, 10 цифрф\n",
    " )\n",
    "print(model.output_shape)\n",
    "print(str(model.summary()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cecdd65d-85e3-4639-b128-63b390d07ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.optimizers.Adadelta(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2f21720c-e21e-4bf7-a60b-369322b97eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x_train,y_train,batch_size=1,epochs=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8e4610ec-130c-4006-9413-bc4e9526c1a7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[5.90196073e-01 5.76470613e-01 5.25490224e-01]\n",
      "   [6.91176474e-01 6.27451003e-01 5.02451003e-01]\n",
      "   [7.51470566e-01 7.27941155e-01 6.55882359e-01]\n",
      "   ...\n",
      "   [8.09803903e-01 8.10784340e-01 8.00000012e-01]\n",
      "   [6.90196097e-01 6.46078408e-01 5.11764705e-01]\n",
      "   [6.52941167e-01 6.13725483e-01 4.76470590e-01]]\n",
      "\n",
      "  [[5.93137264e-01 5.57843149e-01 4.40196067e-01]\n",
      "   [7.11764693e-01 6.62745118e-01 5.31372547e-01]\n",
      "   [7.39215672e-01 6.91176474e-01 5.52941203e-01]\n",
      "   ...\n",
      "   [6.83333337e-01 6.39705896e-01 5.03921568e-01]\n",
      "   [6.37745082e-01 5.80392182e-01 4.08823520e-01]\n",
      "   [6.94607854e-01 6.52450979e-01 5.05392134e-01]]\n",
      "\n",
      "  [[5.83333313e-01 5.43137252e-01 4.33333337e-01]\n",
      "   [6.39705896e-01 5.80882370e-01 4.53431368e-01]\n",
      "   [6.98039234e-01 6.44117653e-01 5.00980377e-01]\n",
      "   ...\n",
      "   [7.17156887e-01 6.77941203e-01 5.40686250e-01]\n",
      "   [6.57843113e-01 6.20588243e-01 4.73529398e-01]\n",
      "   [6.76470578e-01 6.31372571e-01 4.94117647e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[7.45098069e-02 7.05882385e-02 5.49019612e-02]\n",
      "   [2.33333334e-01 2.25490198e-01 2.29411766e-01]\n",
      "   [6.66666701e-02 6.27451017e-02 4.70588244e-02]\n",
      "   ...\n",
      "   [2.11274505e-01 1.83823526e-01 7.15686306e-02]\n",
      "   [5.49019612e-02 5.49019612e-02 5.49019612e-02]\n",
      "   [5.49019612e-02 5.49019612e-02 5.49019612e-02]]\n",
      "\n",
      "  [[4.57843125e-01 4.42156851e-01 3.95098031e-01]\n",
      "   [4.21568632e-01 4.09803927e-01 3.43137264e-01]\n",
      "   [4.30392146e-01 4.17647064e-01 3.55882347e-01]\n",
      "   ...\n",
      "   [5.58823533e-02 5.58823533e-02 5.58823533e-02]\n",
      "   [5.19607849e-02 5.19607849e-02 5.19607849e-02]\n",
      "   [5.00000007e-02 5.00000007e-02 5.00000007e-02]]\n",
      "\n",
      "  [[4.05882359e-01 3.90196085e-01 3.43137264e-01]\n",
      "   [4.27450985e-01 4.31372553e-01 3.76470596e-01]\n",
      "   [4.13235307e-01 4.01470602e-01 3.52450967e-01]\n",
      "   ...\n",
      "   [5.34313731e-02 5.34313731e-02 5.34313731e-02]\n",
      "   [2.23529413e-01 2.23529413e-01 2.23529413e-01]\n",
      "   [5.98039217e-02 5.98039217e-02 5.98039217e-02]]]\n",
      "\n",
      "\n",
      " [[[6.66666687e-01 5.21568656e-01 5.00000000e-01]\n",
      "   [6.47058845e-01 5.56862772e-01 5.33333361e-01]\n",
      "   [9.68627453e-01 9.47058797e-01 9.80392158e-01]\n",
      "   ...\n",
      "   [4.60784316e-01 4.80392158e-01 4.96078432e-01]\n",
      "   [8.13725471e-01 8.49019587e-01 8.76470566e-01]\n",
      "   [8.31372559e-01 8.66666675e-01 8.94117653e-01]]\n",
      "\n",
      "  [[7.15686262e-01 5.13725519e-01 5.47058821e-01]\n",
      "   [6.27451003e-01 4.37254906e-01 4.21568632e-01]\n",
      "   [5.68627477e-01 4.27450985e-01 4.56862748e-01]\n",
      "   ...\n",
      "   [5.05882382e-01 5.21568656e-01 5.47058821e-01]\n",
      "   [8.31372559e-01 8.66666675e-01 8.94117653e-01]\n",
      "   [8.19607854e-01 8.54901969e-01 8.82352948e-01]]\n",
      "\n",
      "  [[6.01960778e-01 7.43137240e-01 7.66666651e-01]\n",
      "   [5.92156887e-01 6.41176462e-01 6.82352960e-01]\n",
      "   [7.29411781e-01 7.72549033e-01 8.35294127e-01]\n",
      "   ...\n",
      "   [5.49019635e-01 5.70588231e-01 6.11764729e-01]\n",
      "   [7.78431356e-01 8.13725471e-01 8.41176450e-01]\n",
      "   [6.47058845e-01 6.84313715e-01 7.19607830e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[9.84313726e-01 9.64705884e-01 7.07843125e-01]\n",
      "   [7.88235307e-01 8.31372559e-01 8.13725471e-01]\n",
      "   [0.00000000e+00 6.07843138e-02 2.01960787e-01]\n",
      "   ...\n",
      "   [7.19607830e-01 7.07843125e-01 6.80392146e-01]\n",
      "   [4.54901963e-01 4.62745100e-01 4.43137258e-01]\n",
      "   [5.62745094e-01 5.66666663e-01 5.43137252e-01]]\n",
      "\n",
      "  [[8.03921595e-02 1.47058830e-01 1.82352945e-01]\n",
      "   [7.45098069e-02 1.39215693e-01 2.54901975e-01]\n",
      "   [2.54901964e-02 1.17647059e-01 1.76470593e-01]\n",
      "   ...\n",
      "   [7.17647076e-01 7.05882370e-01 6.70588255e-01]\n",
      "   [3.58823538e-01 3.43137264e-01 3.47058833e-01]\n",
      "   [6.43137276e-01 6.45098031e-01 6.49019599e-01]]\n",
      "\n",
      "  [[9.80392158e-01 9.80392158e-01 9.80392158e-01]\n",
      "   [6.19607866e-01 6.39215708e-01 6.54901981e-01]\n",
      "   [9.86274481e-01 1.00000000e+00 9.86274481e-01]\n",
      "   ...\n",
      "   [6.88235283e-01 6.72549009e-01 6.68627441e-01]\n",
      "   [7.80392170e-01 7.80392170e-01 7.80392170e-01]\n",
      "   [6.94117665e-01 6.78431392e-01 6.74509823e-01]]]\n",
      "\n",
      "\n",
      " [[[9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   [9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   [9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   ...\n",
      "   [9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   [9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   [9.96078432e-01 9.96078432e-01 9.96078432e-01]]\n",
      "\n",
      "  [[9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   [9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   [9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   ...\n",
      "   [9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   [9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   [9.96078432e-01 9.96078432e-01 9.96078432e-01]]\n",
      "\n",
      "  [[9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   [9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   [9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   ...\n",
      "   [9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   [9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   [9.96078432e-01 9.96078432e-01 9.96078432e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   [9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   [9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   ...\n",
      "   [9.97671545e-01 9.96078432e-01 9.87745106e-01]\n",
      "   [9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   [9.96078432e-01 9.96078432e-01 9.96078432e-01]]\n",
      "\n",
      "  [[9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   [9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   [9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   ...\n",
      "   [9.23077524e-01 9.23077524e-01 9.23077524e-01]\n",
      "   [9.96698856e-01 9.96698856e-01 9.96698856e-01]\n",
      "   [9.80721533e-01 9.80721533e-01 9.80721533e-01]]\n",
      "\n",
      "  [[9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   [9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   [9.96078432e-01 9.96078432e-01 9.96078432e-01]\n",
      "   ...\n",
      "   [7.10497081e-01 7.10497081e-01 7.10497081e-01]\n",
      "   [9.68864918e-01 9.68864918e-01 9.68864918e-01]\n",
      "   [6.70886934e-01 6.70886934e-01 6.70886934e-01]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[2.28431374e-01 2.44117647e-01 2.48039216e-01]\n",
      "   [3.69975477e-01 3.85661751e-01 3.89583319e-01]\n",
      "   [5.58595657e-01 5.93889773e-01 5.89968204e-01]\n",
      "   ...\n",
      "   [2.14711621e-01 2.18633190e-01 2.26476327e-01]\n",
      "   [8.11274499e-02 8.89705867e-02 8.50490183e-02]\n",
      "   [6.97418824e-02 7.75850192e-02 7.36634508e-02]]\n",
      "\n",
      "  [[2.38861442e-01 2.54547715e-01 2.58469284e-01]\n",
      "   [4.19178933e-01 4.34865206e-01 4.38786775e-01]\n",
      "   [5.55842161e-01 5.71528435e-01 5.75450003e-01]\n",
      "   ...\n",
      "   [1.71677768e-01 1.75599337e-01 1.83442473e-01]\n",
      "   [9.35010687e-02 1.01344213e-01 9.74226445e-02]\n",
      "   [5.88235296e-02 6.66666701e-02 6.27451017e-02]]\n",
      "\n",
      "  [[2.96394378e-01 3.12080652e-01 3.16002220e-01]\n",
      "   [4.38195080e-01 4.53881353e-01 4.57802922e-01]\n",
      "   [6.68273211e-01 6.72194779e-01 6.80037916e-01]\n",
      "   ...\n",
      "   [8.61385539e-02 9.00601223e-02 9.79032665e-02]\n",
      "   [6.95752874e-02 7.74184316e-02 7.34968632e-02]\n",
      "   [5.88235296e-02 6.66666701e-02 6.27451017e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[3.35171558e-02 4.13602926e-02 3.74387242e-02]\n",
      "   [5.30081950e-02 6.08513318e-02 5.69297634e-02]\n",
      "   [9.16053951e-02 9.55269635e-02 1.03370100e-01]\n",
      "   ...\n",
      "   [1.01744406e-01 1.01744406e-01 9.39012691e-02]\n",
      "   [7.94730410e-02 7.94730410e-02 7.94730410e-02]\n",
      "   [2.40010336e-01 2.43564263e-01 2.41787300e-01]]\n",
      "\n",
      "  [[3.35171558e-02 4.13602926e-02 3.74387242e-02]\n",
      "   [4.46289070e-02 5.24720438e-02 4.85504754e-02]\n",
      "   [4.82785702e-02 5.22001386e-02 6.00432754e-02]\n",
      "   ...\n",
      "   [6.04721978e-02 6.04721978e-02 5.26290610e-02]\n",
      "   [5.82509972e-02 5.82509972e-02 5.82509972e-02]\n",
      "   [1.27552465e-01 1.31106392e-01 1.29329428e-01]]\n",
      "\n",
      "  [[2.66180299e-02 3.44611667e-02 3.05395983e-02]\n",
      "   [3.07119340e-02 3.85550708e-02 3.46335024e-02]\n",
      "   [5.41685820e-02 5.80901504e-02 6.59332871e-02]\n",
      "   ...\n",
      "   [5.64950965e-02 5.64950965e-02 4.86519597e-02]\n",
      "   [4.31372561e-02 4.31372561e-02 4.31372561e-02]\n",
      "   [5.05993403e-02 5.24873622e-02 5.15433513e-02]]]\n",
      "\n",
      "\n",
      " [[[1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   ...\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]]\n",
      "\n",
      "  [[1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   ...\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]]\n",
      "\n",
      "  [[1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   ...\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   ...\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]]\n",
      "\n",
      "  [[1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   ...\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]]\n",
      "\n",
      "  [[1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   ...\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "   [1.00000000e+00 1.00000000e+00 1.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[3.06648284e-01 3.06801468e-01 1.44087017e-01]\n",
      "   [1.49540439e-01 1.58792898e-01 9.28308815e-02]\n",
      "   [5.82414232e-02 9.28002447e-02 0.00000000e+00]\n",
      "   ...\n",
      "   [3.15900743e-01 3.51286769e-01 2.29442403e-01]\n",
      "   [2.16482848e-01 2.32904404e-01 1.41605392e-01]\n",
      "   [6.36948496e-02 9.49754938e-02 8.45588278e-03]]\n",
      "\n",
      "  [[1.89828426e-01 1.74142152e-01 2.84313727e-02]\n",
      "   [7.58272037e-02 1.12193629e-01 3.75612751e-02]\n",
      "   [1.55177698e-01 1.89368874e-01 8.67953449e-02]\n",
      "   ...\n",
      "   [1.20588236e-01 1.33455887e-01 6.84436262e-02]\n",
      "   [1.50674015e-01 1.44332111e-01 1.07781865e-01]\n",
      "   [1.36274517e-01 1.64001226e-01 2.94424016e-02]]\n",
      "\n",
      "  [[1.45557597e-01 1.49479166e-01 2.03124993e-02]\n",
      "   [1.81985293e-02 4.44852933e-02 5.20833360e-04]\n",
      "   [7.74816200e-02 1.12775736e-01 4.61090691e-02]\n",
      "   ...\n",
      "   [9.01348069e-02 9.01348069e-02 8.22916701e-02]\n",
      "   [1.77573532e-01 1.57965690e-01 1.34436280e-01]\n",
      "   [1.17647059e-01 1.02941178e-01 4.31372561e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[3.27113956e-01 3.19270819e-01 3.23192388e-01]\n",
      "   [3.40196073e-01 3.36274505e-01 3.20588231e-01]\n",
      "   [4.50122535e-01 4.38357830e-01 4.18749988e-01]\n",
      "   ...\n",
      "   [4.19791669e-01 4.00183827e-01 3.76654416e-01]\n",
      "   [4.08700973e-01 3.89093131e-01 3.65563720e-01]\n",
      "   [3.92095596e-01 3.72487754e-01 3.48958343e-01]]\n",
      "\n",
      "  [[3.24080884e-01 3.20159316e-01 3.04473042e-01]\n",
      "   [3.31648290e-01 3.15962017e-01 3.04197311e-01]\n",
      "   [3.99172783e-01 3.95251215e-01 3.79564941e-01]\n",
      "   ...\n",
      "   [4.38051462e-01 4.18443620e-01 3.94914210e-01]\n",
      "   [3.71323526e-01 3.51715684e-01 3.36029410e-01]\n",
      "   [3.56893390e-01 3.37285548e-01 3.21599275e-01]]\n",
      "\n",
      "  [[3.29564959e-01 3.25643390e-01 3.09957117e-01]\n",
      "   [3.65471810e-01 3.53707105e-01 3.34099263e-01]\n",
      "   [3.67677689e-01 3.63756120e-01 3.48069847e-01]\n",
      "   ...\n",
      "   [4.42922801e-01 4.23314959e-01 4.07628685e-01]\n",
      "   [3.73835772e-01 3.62071067e-01 3.42463225e-01]\n",
      "   [3.27481627e-01 3.07873785e-01 2.92187512e-01]]]], shape=(1000, 32, 32, 3), dtype=float32)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x_test=None\n",
    "y_test=None\n",
    "for x_test2, y_test2 in ds_test:\n",
    "    #data=list(ds_test.take(1))\n",
    "    x_test=x_test2\n",
    "    y_test=y_test2\n",
    "    y_test= keras.utils.to_categorical(np.array(y_test), num_classes)\n",
    "    print(x_test)\n",
    "    print(y_test)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4cb85611-6ce1-425e-8bd3-0dd1bcb62ed7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 6.2038 - accuracy: 0.0060 - val_loss: 5.2836 - val_accuracy: 0.0020\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.2181 - accuracy: 0.0070 - val_loss: 5.2829 - val_accuracy: 0.0030\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.2071 - accuracy: 0.0100 - val_loss: 5.2822 - val_accuracy: 0.0020\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.2162 - accuracy: 0.0060 - val_loss: 5.2816 - val_accuracy: 0.0020\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.1145 - accuracy: 0.0040 - val_loss: 5.2811 - val_accuracy: 0.0010\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1529 - accuracy: 0.0080 - val_loss: 5.2807 - val_accuracy: 0.0020\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1802 - accuracy: 0.0060 - val_loss: 5.2802 - val_accuracy: 0.0050\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1898 - accuracy: 0.0070 - val_loss: 5.2799 - val_accuracy: 0.0050\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.3076 - accuracy: 0.0000e+00 - val_loss: 5.2796 - val_accuracy: 0.0090\n",
      "Epoch 2\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.2097 - accuracy: 0.0060 - val_loss: 5.2794 - val_accuracy: 0.0070\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.2174 - accuracy: 0.0070 - val_loss: 5.2792 - val_accuracy: 0.0070\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.1941 - accuracy: 0.0110 - val_loss: 5.2790 - val_accuracy: 0.0080\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.2038 - accuracy: 0.0070 - val_loss: 5.2789 - val_accuracy: 0.0070\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.1212 - accuracy: 0.0040 - val_loss: 5.2788 - val_accuracy: 0.0070\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1506 - accuracy: 0.0080 - val_loss: 5.2787 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1760 - accuracy: 0.0060 - val_loss: 5.2787 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 975ms/step - loss: 6.1889 - accuracy: 0.0070 - val_loss: 5.2788 - val_accuracy: 0.0070\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 6.2683 - accuracy: 0.0069 - val_loss: 5.2790 - val_accuracy: 0.0070\n",
      "Epoch 3\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.2103 - accuracy: 0.0060 - val_loss: 5.2792 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.2322 - accuracy: 0.0050 - val_loss: 5.2793 - val_accuracy: 0.0050\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1915 - accuracy: 0.0110 - val_loss: 5.2794 - val_accuracy: 0.0050\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1937 - accuracy: 0.0070 - val_loss: 5.2796 - val_accuracy: 0.0050\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1033 - accuracy: 0.0040 - val_loss: 5.2797 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1637 - accuracy: 0.0080 - val_loss: 5.2799 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1336 - accuracy: 0.0050 - val_loss: 5.2801 - val_accuracy: 0.0070\n",
      "1/1 [==============================] - 1s 956ms/step - loss: 6.2162 - accuracy: 0.0070 - val_loss: 5.2804 - val_accuracy: 0.0070\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 6.2290 - accuracy: 0.0069 - val_loss: 5.2807 - val_accuracy: 0.0080\n",
      "Epoch 4\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.2090 - accuracy: 0.0060 - val_loss: 5.2811 - val_accuracy: 0.0080\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.2162 - accuracy: 0.0080 - val_loss: 5.2814 - val_accuracy: 0.0080\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1955 - accuracy: 0.0100 - val_loss: 5.2817 - val_accuracy: 0.0080\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1821 - accuracy: 0.0070 - val_loss: 5.2821 - val_accuracy: 0.0090\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1206 - accuracy: 0.0040 - val_loss: 5.2824 - val_accuracy: 0.0110\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1408 - accuracy: 0.0080 - val_loss: 5.2828 - val_accuracy: 0.0100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1643 - accuracy: 0.0060 - val_loss: 5.2832 - val_accuracy: 0.0090\n",
      "1/1 [==============================] - 1s 981ms/step - loss: 6.1695 - accuracy: 0.0070 - val_loss: 5.2836 - val_accuracy: 0.0090\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 6.4116 - accuracy: 0.0069 - val_loss: 5.2841 - val_accuracy: 0.0080\n",
      "Epoch 5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1935 - accuracy: 0.0060 - val_loss: 5.2845 - val_accuracy: 0.0090\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.2262 - accuracy: 0.0060 - val_loss: 5.2850 - val_accuracy: 0.0090\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1865 - accuracy: 0.0100 - val_loss: 5.2854 - val_accuracy: 0.0070\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1969 - accuracy: 0.0070 - val_loss: 5.2859 - val_accuracy: 0.0070\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.0944 - accuracy: 0.0040 - val_loss: 5.2864 - val_accuracy: 0.0070\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1606 - accuracy: 0.0080 - val_loss: 5.2869 - val_accuracy: 0.0070\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1344 - accuracy: 0.0060 - val_loss: 5.2874 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.2019 - accuracy: 0.0070 - val_loss: 5.2880 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 6.2642 - accuracy: 0.0069 - val_loss: 5.2885 - val_accuracy: 0.0060\n",
      "Epoch 6\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.1958 - accuracy: 0.0060 - val_loss: 5.2891 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.2205 - accuracy: 0.0070 - val_loss: 5.2897 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1888 - accuracy: 0.0100 - val_loss: 5.2903 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1860 - accuracy: 0.0070 - val_loss: 5.2909 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1026 - accuracy: 0.0050 - val_loss: 5.2915 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1363 - accuracy: 0.0080 - val_loss: 5.2922 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1421 - accuracy: 0.0050 - val_loss: 5.2929 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 975ms/step - loss: 6.1992 - accuracy: 0.0070 - val_loss: 5.2936 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 6.3029 - accuracy: 0.0069 - val_loss: 5.2943 - val_accuracy: 0.0060\n",
      "Epoch 7\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.1926 - accuracy: 0.0060 - val_loss: 5.2951 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.2132 - accuracy: 0.0070 - val_loss: 5.2959 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1987 - accuracy: 0.0100 - val_loss: 5.2966 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1733 - accuracy: 0.0070 - val_loss: 5.2974 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.0945 - accuracy: 0.0040 - val_loss: 5.2982 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1444 - accuracy: 0.0080 - val_loss: 5.2990 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1416 - accuracy: 0.0060 - val_loss: 5.2998 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 976ms/step - loss: 6.1813 - accuracy: 0.0070 - val_loss: 5.3006 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 6.3324 - accuracy: 0.0069 - val_loss: 5.3015 - val_accuracy: 0.0060\n",
      "Epoch 8\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.1794 - accuracy: 0.0060 - val_loss: 5.3024 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.2130 - accuracy: 0.0060 - val_loss: 5.3033 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1960 - accuracy: 0.0110 - val_loss: 5.3041 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1738 - accuracy: 0.0070 - val_loss: 5.3050 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.0992 - accuracy: 0.0040 - val_loss: 5.3059 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1267 - accuracy: 0.0080 - val_loss: 5.3069 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1510 - accuracy: 0.0050 - val_loss: 5.3078 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 957ms/step - loss: 6.1838 - accuracy: 0.0080 - val_loss: 5.3088 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 6.3057 - accuracy: 0.0000e+00 - val_loss: 5.3097 - val_accuracy: 0.0060\n",
      "Epoch 9\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1935 - accuracy: 0.0070 - val_loss: 5.3107 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.2107 - accuracy: 0.0070 - val_loss: 5.3117 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1676 - accuracy: 0.0100 - val_loss: 5.3127 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1807 - accuracy: 0.0070 - val_loss: 5.3137 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.0966 - accuracy: 0.0040 - val_loss: 5.3147 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1434 - accuracy: 0.0080 - val_loss: 5.3157 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1331 - accuracy: 0.0060 - val_loss: 5.3167 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 957ms/step - loss: 6.1760 - accuracy: 0.0070 - val_loss: 5.3178 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 6.3064 - accuracy: 0.0069 - val_loss: 5.3189 - val_accuracy: 0.0060\n",
      "Epoch 10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.1735 - accuracy: 0.0060 - val_loss: 5.3199 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.2145 - accuracy: 0.0070 - val_loss: 5.3210 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.1830 - accuracy: 0.0100 - val_loss: 5.3220 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1732 - accuracy: 0.0070 - val_loss: 5.3231 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1020 - accuracy: 0.0040 - val_loss: 5.3242 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1256 - accuracy: 0.0080 - val_loss: 5.3253 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1352 - accuracy: 0.0060 - val_loss: 5.3264 - val_accuracy: 0.0060\n",
      "1/1 [==============================] - 1s 930ms/step - loss: 6.1904 - accuracy: 0.0070 - val_loss: 5.3275 - val_accuracy: 0.0050\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 6.1893 - accuracy: 0.0069 - val_loss: 5.3287 - val_accuracy: 0.0050\n",
      "Epoch 11\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1875 - accuracy: 0.0070 - val_loss: 5.3298 - val_accuracy: 0.0050\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1944 - accuracy: 0.0060 - val_loss: 5.3309 - val_accuracy: 0.0050\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1811 - accuracy: 0.0110 - val_loss: 5.3320 - val_accuracy: 0.0050\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1690 - accuracy: 0.0070 - val_loss: 5.3331 - val_accuracy: 0.0050\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.0942 - accuracy: 0.0040 - val_loss: 5.3343 - val_accuracy: 0.0050\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1374 - accuracy: 0.0080 - val_loss: 5.3354 - val_accuracy: 0.0050\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1227 - accuracy: 0.0060 - val_loss: 5.3366 - val_accuracy: 0.0050\n",
      "1/1 [==============================] - 1s 876ms/step - loss: 6.1854 - accuracy: 0.0070 - val_loss: 5.3378 - val_accuracy: 0.0050\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 6.1899 - accuracy: 0.0069 - val_loss: 5.3390 - val_accuracy: 0.0050\n",
      "Epoch 12\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1771 - accuracy: 0.0060 - val_loss: 5.3402 - val_accuracy: 0.0050\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1889 - accuracy: 0.0080 - val_loss: 5.3413 - val_accuracy: 0.0050\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1757 - accuracy: 0.0100 - val_loss: 5.3425 - val_accuracy: 0.0040\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1881 - accuracy: 0.0070 - val_loss: 5.3437 - val_accuracy: 0.0040\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.0782 - accuracy: 0.0040 - val_loss: 5.3449 - val_accuracy: 0.0040\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1210 - accuracy: 0.0080 - val_loss: 5.3461 - val_accuracy: 0.0040\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1321 - accuracy: 0.0060 - val_loss: 5.3473 - val_accuracy: 0.0040\n",
      "1/1 [==============================] - 1s 882ms/step - loss: 6.1798 - accuracy: 0.0070 - val_loss: 5.3486 - val_accuracy: 0.0040\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 6.2556 - accuracy: 0.0069 - val_loss: 5.3498 - val_accuracy: 0.0040\n",
      "Epoch 13\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1810 - accuracy: 0.0070 - val_loss: 5.3511 - val_accuracy: 0.0040\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1983 - accuracy: 0.0080 - val_loss: 5.3523 - val_accuracy: 0.0040\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1719 - accuracy: 0.0100 - val_loss: 5.3535 - val_accuracy: 0.0040\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1676 - accuracy: 0.0070 - val_loss: 5.3548 - val_accuracy: 0.0040\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.0850 - accuracy: 0.0040 - val_loss: 5.3560 - val_accuracy: 0.0040\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1158 - accuracy: 0.0080 - val_loss: 5.3573 - val_accuracy: 0.0040\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1267 - accuracy: 0.0060 - val_loss: 5.3586 - val_accuracy: 0.0040\n",
      "1/1 [==============================] - 1s 915ms/step - loss: 6.1748 - accuracy: 0.0070 - val_loss: 5.3598 - val_accuracy: 0.0040\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 6.2447 - accuracy: 0.0069 - val_loss: 5.3611 - val_accuracy: 0.0040\n",
      "Epoch 14\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't decrement id ref count (unable to extend file properly)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [116], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_train,y_train \u001b[38;5;129;01min\u001b[39;00m ds_train:\n\u001b[0;32m      6\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mto_categorical(y_train, num_classes)\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaved_model_CNN/learn_epoch_start=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m    \u001b[38;5;66;03m# (x_test,y_test)=ds_test.take(100)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(x_train,y_train,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,validation_data\u001b[38;5;241m=\u001b[39m(x_test,y_test))\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\h5py\\_hl\\files.py:552\u001b[0m, in \u001b[0;36mFile.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39mvalid:\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;66;03m# We have to explicitly murder all open objects related to the file\u001b[39;00m\n\u001b[0;32m    548\u001b[0m \n\u001b[0;32m    549\u001b[0m     \u001b[38;5;66;03m# Close file-resident objects first, then the files.\u001b[39;00m\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;66;03m# Otherwise we get errors in MPI mode.\u001b[39;00m\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39m_close_open_objects(h5f\u001b[38;5;241m.\u001b[39mOBJ_LOCAL \u001b[38;5;241m|\u001b[39m \u001b[38;5;241m~\u001b[39mh5f\u001b[38;5;241m.\u001b[39mOBJ_FILE)\n\u001b[1;32m--> 552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39m_close_open_objects(h5f\u001b[38;5;241m.\u001b[39mOBJ_LOCAL \u001b[38;5;241m|\u001b[39m h5f\u001b[38;5;241m.\u001b[39mOBJ_FILE)\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    555\u001b[0m     _objects\u001b[38;5;241m.\u001b[39mnonlocal_close()\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5f.pyx:360\u001b[0m, in \u001b[0;36mh5py.h5f.FileID._close_open_objects\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't decrement id ref count (unable to extend file properly)"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(\"x_train=\",x_train.shape,\"y_train\",y_train.shape)\n",
    "model.save(\"saved_model_CNN/learn_epoch_start.h5\")\n",
    "for i in range(1,20):\n",
    "    print(\"Epoch \"+str(i))\n",
    "    for x_train,y_train in ds_train:\n",
    "        y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "        \n",
    "        model.save('saved_model_CNN/learn_epoch_start='+str(i)+\".h5\")\n",
    "        \n",
    "       # (x_test,y_test)=ds_test.take(100)\n",
    "        model.fit(x_train,y_train,batch_size=1000,epochs=1,shuffle=True,validation_data=(x_test,y_test))\n",
    "        #results=model.evaluate(x_test,y_test,batch_size=50,verbose=2)\n",
    "        #print(str(results))\n",
    "        #,validation_data=(x_test,y_test)\n",
    "    model.save('saved_model_CNN/learn_epoch_end='+str(i)+\".h5\")\n",
    "#results=model.evaluate(x_test,y_test,batch_size=50,verbose=2)\n",
    "#print(str(results))\n",
    "model.save(\"saved_model_CNN/learn_done.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d414d1e4-01df-4018-9c15-6d3af2ca3bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [66], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i))\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved_model_CNN2/CIFAR100_learn_epoch_start=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x_train,y_train,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,validation_data\u001b[38;5;241m=\u001b[39m(\u001b[43mx_test\u001b[49m,y_test))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#,validation_data=(x_test,y_test)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved_model_CNN2/CIFAR100_learn_epoch_end=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "#Без dropout было явное переобучение train 90 пртив test 45\n",
    "#print(\"x_train=\",x_train.shape,\"y_train\",y_train.shape)\n",
    "model.save(\"saved_model_CNN2/CIFAR100_learn_epoch_start.h5\")\n",
    "for i in range(1,10):\n",
    "    print(\"Epoch \"+str(i))\n",
    "    model.save('saved_model_CNN2/CIFAR100_learn_epoch_start='+str(i)+\".h5\")\n",
    "    model.fit(x_train,y_train,batch_size=25,epochs=1,shuffle=True,validation_data=(x_test,y_test))\n",
    "    #,validation_data=(x_test,y_test)\n",
    "    \n",
    "    \n",
    "    model.save('saved_model_CNN2/CIFAR100_learn_epoch_end='+str(i)+\".h5\")\n",
    "results=model.evaluate(x_test,y_test,batch_size=50,verbose=2)\n",
    "print(str(results))\n",
    "model.save(\"saved_model_CNN2/CIFAR100_learn_done.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed7edec0-1669-4bd8-b6a3-604a53d90ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"saved_model_CNN2/CIFAR100_learn_epoch_end=8.h5\")\n",
    "model.compile(\n",
    "    loss=losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08bed29c-82f0-4169-bbe2-523a994f4f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " 614/2000 [========>.....................] - ETA: 16s - loss: 3.1998 - accuracy: 0.2230"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i))\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved_model_CNN3/CIFAR100_learn_epoch_start=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#,validation_data=(x_test,y_test)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved_model_CNN3/CIFAR100_learn_epoch_end=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:1158\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m     logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m-> 1158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\generic_utils.py:1051\u001b[0m, in \u001b[0;36mProgbar.update\u001b[1;34m(self, current, values, finalize)\u001b[0m\n\u001b[0;32m   1048\u001b[0m         info \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1050\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m info\n\u001b[1;32m-> 1051\u001b[0m     \u001b[43mio_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline_break\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1052\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\io_utils.py:80\u001b[0m, in \u001b[0;36mprint_msg\u001b[1;34m(message, line_break)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(message)\n\u001b[1;32m---> 80\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(message)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\iostream.py:488\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(evt\u001b[38;5;241m.\u001b[39mset)\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;66;03m# and give a timeout to avoid\u001b[39;00m\n\u001b[1;32m--> 488\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mevt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush_timeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    489\u001b[0m         \u001b[38;5;66;03m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIOStream.flush timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39m__stderr__)\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    579\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 581\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tf\\lib\\threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 316\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    318\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Без dropout было явное переобучение train 90 пртив test 45\n",
    "#print(\"x_train=\",x_train.shape,\"y_train\",y_train.shape)\n",
    "model.save(\"saved_model_CNN3/CIFAR100_learn_epoch_start.h5\")\n",
    "for i in range(1,3):\n",
    "    print(\"Epoch \"+str(i))\n",
    "    model.save('saved_model_CNN3/CIFAR100_learn_epoch_start='+str(i)+\".h5\")\n",
    "    model.fit(x_train,y_train,batch_size=25,epochs=1,shuffle=True,validation_data=(x_test,y_test))\n",
    "    #,validation_data=(x_test,y_test)\n",
    "    \n",
    "    \n",
    "    model.save('saved_model_CNN3/CIFAR100_learn_epoch_end='+str(i)+\".h5\")\n",
    "results=model.evaluate(x_test,y_test,batch_size=50,verbose=2)\n",
    "print(str(results))\n",
    "model.save(\"saved_model_CNN3/CIFAR100_learn_done.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb69608-41e0-4105-b3c8-b0447329e157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x_train,y_train,batch_size=32,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80a0a9c-40f1-460b-b3ed-4740bb659edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25924428-dbef-47ca-9819-544f29745779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights(\"saved_model3/ECIFAR100_learn_epoch_start.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6186a282-2204-4b0e-8bd2-c08bd411cf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.0398 - accuracy: 0.9875 - 1s/epoch - 3ms/step\n",
      "[0.039796166121959686, 0.987500011920929]\n",
      "8440\n",
      "(28, 28, 3)\n",
      "(28, 28, 1)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results=model.evaluate(x_test,y_test,batch_size=32,verbose=2)\n",
    "print(str(results))\n",
    "value=np.random.randint(0,10000)\n",
    "print(value)\n",
    "for id in range(len(y_train)):\n",
    "    #print(labels[id])\n",
    "    #break\n",
    "    #22 - M big\n",
    "    if(y_train.argmax()==7):\n",
    "        value=id\n",
    "        break\n",
    "        \n",
    "\n",
    "\n",
    "#print(x_train[value].shape)\n",
    "\n",
    "single=x_train[value]\n",
    "image=np.zeros((28,28,3))\n",
    "print(image.shape)\n",
    "\n",
    "for y in range(0,image.shape[0]):\n",
    "    for x in range(0,image.shape[1]):\n",
    "        for c in range(0,image.shape[2]):\n",
    "            image[y,x,c]=single[y][x]\n",
    "\n",
    "\n",
    "\n",
    "print(single.shape)\n",
    "#print(single)\n",
    "\n",
    "singleReady=np.zeros((1,28,28))\n",
    "\n",
    "for y in range(0,image.shape[0]):\n",
    "    for x in range(0,image.shape[1]):\n",
    "            singleReady[0][y][x]=single[y][x]\n",
    "\n",
    "print(model.predict(singleReady,batch_size=1).argmax())\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d90177ee-7111-49bd-87de-fd4323a5947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_model_CNN/CIFAR100_byclass_done.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28f6ad4b-c994-4c6b-9412-9b84fa1e51c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results=model.evaluate(x_test,y_test,batch_size=32,verbose=2)\n",
    "#print(str(results))\n",
    "#value=np.random.randint(0,10000)\n",
    "\n",
    "id=22\n",
    "for v in y_train:\n",
    "    if(v.argmax()==id):\n",
    "        print(id)\n",
    "        ShowImage(v)\n",
    "        break\n",
    "        #id+=1\n",
    "currentIteration=0\n",
    "'''for v in y_train:\n",
    "    if(v==id):\n",
    "        print(id,v)\n",
    "        ShowImage(v)\n",
    "        currentIteration+=1\n",
    "        id+=1    \n",
    "    if(currentIteration==10):\n",
    "        break'''\n",
    "\n",
    "\n",
    "def ShowImage(value:int):\n",
    "    print(x_train[value].shape)\n",
    "\n",
    "    single=x_train[value]\n",
    "    image=np.zeros((28,28,3))\n",
    "    print(image.shape)\n",
    "\n",
    "    for y in range(0,image.shape[0]):\n",
    "        for x in range(0,image.shape[1]):\n",
    "            for c in range(0,image.shape[2]):\n",
    "                image[y,x,c]=single[y*28+x]\n",
    "\n",
    "\n",
    "\n",
    "    #print(single.shape)\n",
    "    #print(single)\n",
    "\n",
    "    #singleReady=np.zeros((1,28*28))\n",
    "\n",
    "    #for y in range(0,image.shape[0]):\n",
    "    #    for x in range(0,image.shape[1]):\n",
    "    #            singleReady[0][y*28+x]=single[y*28+x]\n",
    "\n",
    "    #print(model.predict(singleReady,batch_size=1).argmax())\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86d82074-35d5-4ed4-842c-8f9e6e7a81ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "IMG = np.asarray(Image.open('E:/JupyterLab/Tensorflow_FKI_fall_2022/2022.10.07/Segmented/9.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95b55033-6874-4064-a576-4b032543f4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n",
      "(1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(IMG)\n",
    "plt.show()\n",
    "print(IMG.shape)\n",
    "\n",
    "IMG_2=np.zeros((1,28,28),dtype=\"float32\")\n",
    "\n",
    "for x in range(28):\n",
    "    for y in range(28):\n",
    "        IMG_2[0][x][y]=IMG[x][y][0]/255.\n",
    "print(IMG_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c89da332-81e7-4a97-81fd-01a53ed022a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(IMG_2,batch_size=1).argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4873c98d-4e6f-4e4a-a4f8-74653017b9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
