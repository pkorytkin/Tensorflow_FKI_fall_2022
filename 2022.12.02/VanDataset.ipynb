{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51261624-02b8-49be-b7bf-38620150ec79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PlayerBook4\\miniconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "#Используем костыль для исправления IntelliSense для keras по гайду:\n",
    "#https://stackoverflow.com/questions/71000250/import-tensorflow-keras-could-not-be-resolved-after-upgrading-to-tensorflow-2\n",
    "import keras.api._v2.keras as keras\n",
    "from keras import layers\n",
    "from keras import losses\n",
    "#from keras.datasets import CIFAR100\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f419e81f-16e8-49d2-b3ac-1c2328bd8ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 32, 32, 3)\n",
      "(56, 32, 32, 3)\n",
      "9\n",
      "x_train:\n",
      "(100, 32, 32, 3) uint8\n",
      "(605, 32, 32, 3) uint8\n",
      "new x_train:\n",
      "(705, 32, 32, 3)\n",
      "y_train:\n",
      "(705, 1)\n",
      "x_test:\n",
      "(10, 32, 32, 3)\n",
      "10\n",
      "test:\n",
      "(56, 32, 32, 3)\n",
      "9\n",
      "10\n",
      "new x_test:\n",
      "(66, 32, 32, 3)\n",
      "\n",
      "Train X=(705, 32, 32, 3, 1), y=(705, 11)\n",
      "Train X=(705, 32, 32, 3, 1), y=(705, 11)\n",
      "Test X=(66, 32, 32, 3, 1), y=(66, 11)\n",
      "(32, 32, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "x_train=x_train[:100]\n",
    "y_train=y_train[:100]\n",
    "\n",
    "x_test=x_train[:10]\n",
    "y_test=y_train[:10]\n",
    "train=None\n",
    "test=None\n",
    "with open('train.npy', 'rb') as f:\n",
    "    train = np.load(f)\n",
    "    print(train.shape)\n",
    "with open('test.npy', 'rb') as f:\n",
    "    test = np.load(f)\n",
    "    print(test.shape)\n",
    "\n",
    "print(y_train.max())\n",
    "print(\"x_train:\")\n",
    "print(x_train.shape,x_train.dtype)\n",
    "print(train.shape,train.dtype)\n",
    "shapeSize=x_train.shape[0]\n",
    "\n",
    "train_y=np.full((train.shape[0],1),10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_train=np.append(x_train,train).reshape((shapeSize+train.shape[0],32,32,3))\n",
    "y_train=np.append(y_train,train_y).reshape((shapeSize+train.shape[0],1))\n",
    "print(\"new x_train:\")\n",
    "print(x_train.shape)\n",
    "\n",
    "print(\"y_train:\")\n",
    "print(y_train.shape)\n",
    "\n",
    "#print(\"Shape\"+str((train.shape[0],1).shape))\n",
    "\n",
    "print(\"x_test:\")\n",
    "print(x_test.shape)\n",
    "#x_train, y_train = extract_training_samples('letters')\n",
    "print(y_train.max())\n",
    "print(\"test:\")\n",
    "print(test.shape)\n",
    "\n",
    "print(y_test.max())\n",
    "shapeSize=x_test.shape[0]\n",
    "x_test=np.append(x_test,test).reshape(shapeSize+test.shape[0],32,32,3)\n",
    "\n",
    "test_y=np.full((test.shape[0],1),10)\n",
    "\n",
    "y_test=np.append(y_test,test_y).reshape((shapeSize+56,1))\n",
    "#x_train, y_train = extract_training_samples('letters')\n",
    "print(y_test.max())\n",
    "print(\"new x_test:\")\n",
    "print(x_test.shape)\n",
    "\n",
    "num_classes=11\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "#cv2.imshow('graycsale image',x_train[x_train.shape[0]-2])\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "x_train=x_train.astype('float32')/255.0\n",
    "x_test=x_test.astype('float32')/255.0\n",
    "\n",
    "test=test.astype('float32')/255.0\n",
    "train=train.astype('float32')/255.0\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "test=np.expand_dims(test, -1)\n",
    "train=np.expand_dims(train, -1)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "test_y = keras.utils.to_categorical(test_y, num_classes)\n",
    "train_y = keras.utils.to_categorical(train_y, num_classes)\n",
    "#x_train_l, y_train_l = extract_training_samples('letters')\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"Train X=%s, y=%s\"%(x_train.shape,y_train.shape))\n",
    "#print(\"Train Letters X=%s, y=%s\"%(x_train_l.shape,y_train_l.shape))\n",
    "#print(\"Test X=%s, y=%s\"%(x_test1.shape,y_test.shape))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Train X=%s, y=%s\"%(x_train.shape,y_train.shape))\n",
    "print(\"Test X=%s, y=%s\"%(x_test.shape,y_test.shape))\n",
    "print(x_test[0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e875fef7-cb87-49c5-8e57-c2ec0f74dafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Convolution2D, Input\n",
    "\n",
    "def define_skip_model():\n",
    "    inputs = keras.Input(shape=input_shape, name=\"img\")\n",
    "    x = layers.BatchNormalization()(inputs)\n",
    "    x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    #x = layers.Dropout(0.2)(x)\n",
    "    block_1_output = layers.MaxPooling2D(3)(x)\n",
    "    #block_1_output = layers.BatchNormalization()(block_1_output)\n",
    "    \n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_1_output)\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    #x = layers.Dropout(0.2)(x)\n",
    "    block_2_output = layers.concatenate([x, block_1_output])\n",
    "    #block_2_output = layers.BatchNormalization()(block_2_output)\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\")(block_2_output)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    #x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs, outputs, name=\"toy_resnet\")\n",
    "    return model\n",
    "model=define_skip_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48e22845-bf43-46bd-86c3-7a749b154689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 32, 32, 3, 1) (56, 11)\n",
      "(605, 32, 32, 3, 1) (605, 11)\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.optimizers.Adam(lr=0.01),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "print(test.shape,test_y.shape)\n",
    "print(train.shape,train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f4d5c5-0b2d-4fb0-b4cf-2bd356ff6126",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f1bffb5-b5f9-4181-9443-d8dc2ce9ff1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 439ms/step - loss: 0.9197 - accuracy: 0.8355 - val_loss: 0.0408 - val_accuracy: 0.9821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1994b3461c0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=500,epochs=1,shuffle=True,validation_data=(test,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "998ce3c2-fa65-43fb-b85c-24d61a90e290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 3)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "im = cv2.imread(\"../../VanDataset/van.jpg\")\n",
    "im=im.astype('float32')/255.0\n",
    "im=im.reshape((1,32,32,3))\n",
    "print(im.shape)\n",
    "#print(model.predict(x_test,batch_size=1).argmax())\n",
    "print(model.predict(im,batch_size=1).argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abf5653-3969-4934-96ca-537cc35fa0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
